{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sqlite3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[43msqlite3\u001b[49m\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv30_koondkorpus_sentences_verb_pattern_obl_20240327-194533.db\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[1;32m      2\u001b[0m cur \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcursor()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sqlite3' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "connection = sqlite3.connect(\"v30_koondkorpus_sentences_verb_pattern_obl_20240327-194533.db\")  \n",
    "cur = connection.cursor()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sqlalchemy\n",
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text, MetaData, Table, select, and_\n",
    "import pandas as pd\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "\n",
    "\n",
    "class V30:\n",
    "    _e = None\n",
    "    _conn = None\n",
    "    _matadata = None\n",
    "    _te = TransactionEncoder()\n",
    "    \n",
    "    _t = {}\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        # relative path\n",
    "        self._engine = create_engine(f'sqlite:///{file_path}')\n",
    "        self._metadata = MetaData()\n",
    "        self._conn = self._engine.connect()\n",
    "        self.__init_tables()\n",
    "        \n",
    "        \n",
    "    def __init_tables(self):\n",
    "        q = text(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "        res = self._conn.execute(q).all()\n",
    "       \n",
    "        \n",
    "        tables = [str(r[0]) for r in res]\n",
    "        for t in tables:\n",
    "            self._t[t] = Table(t, self._metadata, autoload_with=self._engine)\n",
    "        \n",
    "   \n",
    "    def execute_text(self, q):\n",
    "        return self._conn.execute(text(q))\n",
    "    \n",
    "    \n",
    "    def execute(self, stmt):\n",
    "        return self._conn.execute(stmt)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_transactions(self, verb, verb_compound, columns=[], skip_deprels=[], include_deprels=[]):\n",
    "        \"\"\"\n",
    "        Fetches transactions from the database and returns them as an array of dictionaries, each representing a transaction.\n",
    "\n",
    "        Parameters:\n",
    "        - verb (str): The main verb to filter transactions by.\n",
    "        - verb_compound (str): Additional compound verb information for filtering.\n",
    "        - columns (list of str, optional): Specifies which columns to include in each returned dictionary. If empty, all columns are included.\n",
    "        - skip_deprels (list of str, optional): Dependency relations to exclude from the results.\n",
    "        - include_deprels (list of str, optional): Dependency relations to include in the results. \n",
    "            If both skip_deprels and include_deprels are provided, include_deprels takes precedence.\n",
    "\n",
    "        Returns:\n",
    "        - list of dicts: A list where each dictionary represents a transaction, \n",
    "        structured according to the specified 'columns', or all transaction data \n",
    "        if 'columns' is empty or not provided. Transactions are grouped by 'head_id'.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        TransactionHead = self._t['transaction_head']\n",
    "        Transaction = self._t['transaction']\n",
    "        \n",
    "        \n",
    "        where_filters = [TransactionHead.c.verb == verb]\n",
    "        where_filters.append(TransactionHead.c.verb_compound == verb_compound)\n",
    "        \n",
    "        if isinstance(skip_deprels, list) and len(skip_deprels):\n",
    "            where_filters.append(Transaction.c.deprel.notin_(skip_deprels))\n",
    "        \n",
    "        if isinstance(include_deprels, list) and len(include_deprels):\n",
    "            where_filters.append(Transaction.c.deprel.in_(include_deprels))  \n",
    "    \n",
    "        # maybe some transaction_head field should be also includes in results eg TransactionHead.deprel\n",
    "        selections = [Transaction]\n",
    "        \n",
    "        stmt = select(*selections)\\\n",
    "            .join(TransactionHead, TransactionHead.c.id == Transaction.c.head_id)\\\n",
    "            .where(and_(*where_filters))\\\n",
    "            .order_by(Transaction.c.head_id, Transaction.c.loc)\n",
    "            \n",
    "        transactions = {}\n",
    "        for res in self.execute(stmt).mappings():\n",
    "            res = dict(res)\n",
    "            # group by transaction_head\n",
    "            if res[\"head_id\"] not in transactions:\n",
    "                transactions[res[\"head_id\"]] = []\n",
    "                \n",
    "            r_dict = dict(res)\n",
    "\n",
    "            if columns:\n",
    "                for key in list(r_dict.keys()):\n",
    "                    if key not in columns:\n",
    "                        del r_dict[key]\n",
    "                        \n",
    "            transactions[res[\"head_id\"]].append(r_dict)\n",
    "            \n",
    "        return list(transactions.values())\n",
    "    \n",
    "   \n",
    "    def dict_to_apriory(self, transactions):\n",
    "        \"\"\"\n",
    "        Converts transaction data into a format suitable for Apriori algorithm processing.\n",
    "\n",
    "        Parameters:\n",
    "        - transactions (list of list of dicts): The transaction data, where each transaction is a list of row dictionaries.\n",
    "\n",
    "        Returns:\n",
    "        - list of list of tuples: A dataset where each transaction is represented as a list of tuples, with each tuple containing the row values.\n",
    "        \"\"\"\n",
    "        return  [ [ tuple(row.values()) for row in tr] for tr in transactions ]\n",
    "        \n",
    "    \n",
    "    def apriory(self, dataset, min_support=0.5, use_colnames=True):\n",
    "        \"\"\"\n",
    "        Applies the Apriori algorithm on the dataset to find frequent itemsets based on a minimum support threshold.\n",
    "\n",
    "        Parameters:\n",
    "        - dataset (list of list of items): The transaction dataset for itemset generation.\n",
    "        - min_support (float, optional): The minimum support threshold for itemsets to be considered frequent. Default is 0.5.\n",
    "        - use_colnames (bool, optional): Indicates whether to use column names for itemset generation. Default is True.\n",
    "\n",
    "        Displays:\n",
    "        - A DataFrame of frequent itemsets sorted by their support values in descending order.\n",
    "        - The transformed dataset DataFrame used for Apriori algorithm.\n",
    "        \"\"\"\n",
    "        \n",
    "        print('min_support:', min_support)\n",
    "        te_ary = self._te.fit(dataset).transform(dataset)\n",
    "        df = pd.DataFrame(te_ary, columns=self._te.columns_)\n",
    "        display(apriori(df, min_support=min_support, use_colnames=use_colnames).sort_values('support', ascending=False))\n",
    "        display(df)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hh/s3kkmqlx7sb3js2bqncf08s00000gn/T/ipykernel_15534/4227891811.py:32: SAWarning: Skipped unsupported reflection of expression-based index `verb_compound`\n",
      "  self._t[t] = Table(t, self._metadata, autoload_with=self._engine)\n",
      "/var/folders/hh/s3kkmqlx7sb3js2bqncf08s00000gn/T/ipykernel_15534/4227891811.py:32: SAWarning: Skipped unsupported reflection of expression-based index `verb`\n",
      "  self._t[t] = Table(t, self._metadata, autoload_with=self._engine)\n",
      "/var/folders/hh/s3kkmqlx7sb3js2bqncf08s00000gn/T/ipykernel_15534/4227891811.py:32: SAWarning: Skipped unsupported reflection of expression-based index `loc`\n",
      "  self._t[t] = Table(t, self._metadata, autoload_with=self._engine)\n",
      "/var/folders/hh/s3kkmqlx7sb3js2bqncf08s00000gn/T/ipykernel_15534/4227891811.py:32: SAWarning: Skipped unsupported reflection of expression-based index `sentence_id`\n",
      "  self._t[t] = Table(t, self._metadata, autoload_with=self._engine)\n"
     ]
    }
   ],
   "source": [
    "v30 = V30(\"v30_koondkorpus_sentences_verb_pattern_obl_20240327-194533.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = v30.get_transactions(verb='kirjutama', verb_compound='alla', columns=['deprel','feats'], skip_deprels=['punct', 'cc'])\n",
    "display(transactions[:1])\n",
    "\n",
    "dataset = v30.dict_to_apriory(transactions)\n",
    "v30.apriory(dataset, min_support=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
