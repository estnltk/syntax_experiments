{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7c0c5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from estnltk import Text\n",
    "from estnltk_neural.taggers import StanzaSyntaxTagger\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import csv\n",
    "import sqlite3\n",
    "from estnltk.converters import text_to_json\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36389961",
   "metadata": {},
   "source": [
    "Alustuseks fraasimustrid, mis peaksid olema korrektsed. Fraasimustrid on tekstifailis, igal real üks muster. Esituskuju on järgnev: id-ner/timex/other-ülemuse_id-deprel-POS eraldatuna tühikutega. Eri sõnade info on eraldatud komadega. Juhul, kui POS on mitmene, esitatakse variandid püstkriipsuga eraldatult. Indekseid mustrites ei esitata, sest fraasisiseste otsingut korral võivad tekkida ebakõlad. Liikmete järjestus vastab järjestusele tekstis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "b45409c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 PER 0 root H,2 OTHER 1 flat H,3 OTHER 1 flat H\n",
      "1 LOC 2 nmod G,2 OTHER 0 root S\n",
      "1 LOC 2 nmod H,2 OTHER 0 root D\n",
      "1 LOC 2 nmod H,2 OTHER 0 root H\n",
      "1 LOC 2 nmod H,2 OTHER 0 root S\n",
      "1 ORG 2 nmod S,2 OTHER 0 root S\n",
      "1 ORG 2 nmod Y,2 OTHER 0 root S\n",
      "1 LOC 2 amod G,2 OTHER 0 root S\n",
      "1 LOC 2 amod H,2 OTHER 0 root S\n",
      "1 LOC 2 nmod H,2 OTHER 0 root S,3 OTHER 2 appos H,4 OTHER 3 flat H\n",
      "1 ORG 2 nmod H,2 OTHER 0 root S,3 OTHER 2 appos H,4 OTHER 3 flat S\n",
      "1 LOC 2 nmod H,2 OTHER 0 root S,3 OTHER 2 appos H,4 OTHER 3 flat Y\n",
      "1 LOC 2 nmod H,2 OTHER 0 root S,3 OTHER 2 appos S,4 OTHER 3 flat H\n",
      "1 ORG 2 nmod S,2 OTHER 0 root S,3 OTHER 2 appos H,4 OTHER 3 flat H\n",
      "1 ORG 2 nmod S,2 OTHER 0 root S,3 OTHER 2 appos S,4 OTHER 3 flat H\n",
      "1 LOC 2 nmod Y,2 OTHER 0 root S,3 OTHER 2 appos H,4 OTHER 3 flat H\n",
      "1 LOC 2 obl H,2 OTHER 3 acl A,3 OTHER 0 root S\n",
      "1 PER 2 nmod H,2 OTHER 0 root S,3 OTHER 2 nmod S\n",
      "1 LOC 2 obl A,2 OTHER 3 acl A,3 OTHER 0 root S\n",
      "1 LOC 2 obl Y,2 OTHER 3 acl A,3 OTHER 0 root S\n",
      "1 OTHER 3 advmod D|I,2 PER 3 nmod H,3 OTHER 0 root S\n",
      "1 OTHER 3 advmod D,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 OTHER 3 advmod S,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 LOC 3 amod H,2 OTHER 3 amod A,3 OTHER 0 root S\n",
      "1 LOC 3 amod H,2 OTHER 3 amod O,3 OTHER 0 root S\n",
      "1 OTHER 3 amod A,2 LOC 3 nmod G,3 OTHER 0 root S\n",
      "1 OTHER 3 amod A,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 TIMEX 3 amod A,2 LOC 3 nmod Y,3 OTHER 0 root S\n",
      "1 OTHER 3 amod O,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 OTHER 3 det P|N,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 OTHER 3 det A,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 OTHER 3 det P,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 LOC 3 nmod H,2 OTHER 3 amod A,3 OTHER 0 root S\n",
      "1 LOC 3 nmod H,2 OTHER 3 amod C,3 OTHER 0 root S\n",
      "1 LOC 3 nmod H,2 OTHER 3 amod O,3 OTHER 0 root S\n",
      "1 LOC 3 nmod H,2 OTHER 3 amod U,3 OTHER 0 root S\n",
      "1 ORG 3 nmod Y,2 OTHER 3 amod A,3 OTHER 0 root S\n",
      "1 LOC 3 nmod Y,2 OTHER 3 amod C,3 OTHER 0 root S\n",
      "1 ORG 3 nmod Y,2 OTHER 3 amod U,3 OTHER 0 root S\n",
      "1 LOC 3 nmod H,2 OTHER 3 nmod S,3 OTHER 0 root S\n",
      "1 LOC 3 nmod H,2 OTHER 3 nmod Y,3 OTHER 0 root S\n",
      "1 OTHER 3 nmod P,2 LOC 3 nmod H,3 OTHER 0 root S\n",
      "1 TIMEX 3 nmod S,2 LOC 3 nmod H,3 OTHER 0 root S\n"
     ]
    }
   ],
   "source": [
    "# patterns are kept in a list of strings\n",
    "patterns = None\n",
    "\n",
    "with open('correct_tree_patterns.txt', 'r') as f:\n",
    "    patterns = [line.rstrip() for line in f]\n",
    "\n",
    "for pattern in patterns:\n",
    "    print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d540f34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0 root H,2 1 flat H,3 1 flat H\n",
      "1 2 nmod G,2 0 root S\n",
      "1 2 nmod H,2 0 root D\n",
      "1 2 nmod H,2 0 root H\n",
      "1 2 nmod H,2 0 root S\n",
      "1 2 nmod S,2 0 root S\n",
      "1 2 nmod Y,2 0 root S\n",
      "1 2 amod G,2 0 root S\n",
      "1 2 amod H,2 0 root S\n",
      "1 2 nmod H,2 0 root S,3 2 appos H,4 3 flat H\n",
      "1 2 nmod H,2 0 root S,3 2 appos H,4 3 flat S\n",
      "1 2 nmod H,2 0 root S,3 2 appos H,4 3 flat Y\n",
      "1 2 nmod H,2 0 root S,3 2 appos S,4 3 flat H\n",
      "1 2 nmod S,2 0 root S,3 2 appos H,4 3 flat H\n",
      "1 2 nmod S,2 0 root S,3 2 appos S,4 3 flat H\n",
      "1 2 nmod Y,2 0 root S,3 2 appos H,4 3 flat H\n",
      "1 2 obl H,2 3 acl A,3 0 root S\n",
      "1 2 nmod H,2 0 root S,3 2 nmod S\n",
      "1 2 obl A,2 3 acl A,3 0 root S\n",
      "1 2 obl Y,2 3 acl A,3 0 root S\n",
      "1 3 advmod D|I,2 3 nmod H,3 0 root S\n",
      "1 3 advmod D,2 3 nmod H,3 0 root S\n",
      "1 3 advmod S,2 3 nmod H,3 0 root S\n",
      "1 3 amod H,2 3 amod A,3 0 root S\n",
      "1 3 amod H,2 3 amod O,3 0 root S\n",
      "1 3 amod A,2 3 nmod G,3 0 root S\n",
      "1 3 amod A,2 3 nmod H,3 0 root S\n",
      "1 3 amod A,2 3 nmod Y,3 0 root S\n",
      "1 3 amod O,2 3 nmod H,3 0 root S\n",
      "1 3 det P|N,2 3 nmod H,3 0 root S\n",
      "1 3 det A,2 3 nmod H,3 0 root S\n",
      "1 3 det P,2 3 nmod H,3 0 root S\n",
      "1 3 nmod H,2 3 amod A,3 0 root S\n",
      "1 3 nmod H,2 3 amod C,3 0 root S\n",
      "1 3 nmod H,2 3 amod O,3 0 root S\n",
      "1 3 nmod H,2 3 amod U,3 0 root S\n",
      "1 3 nmod Y,2 3 amod A,3 0 root S\n",
      "1 3 nmod Y,2 3 amod C,3 0 root S\n",
      "1 3 nmod Y,2 3 amod U,3 0 root S\n",
      "1 3 nmod H,2 3 nmod S,3 0 root S\n",
      "1 3 nmod H,2 3 nmod Y,3 0 root S\n",
      "1 3 nmod P,2 3 nmod H,3 0 root S\n",
      "1 3 nmod S,2 3 nmod H,3 0 root S\n"
     ]
    }
   ],
   "source": [
    "patterns_simplified = []\n",
    "\n",
    "for pattern in patterns:\n",
    "    pieces = [wrd.split() for wrd in pattern.split(',')]\n",
    "    for piece in pieces:\n",
    "        piece.pop(1)\n",
    "\n",
    "    for i in range(len(pieces)):\n",
    "        pieces[i] = ' '.join(pieces[i])\n",
    "    patterns_simplified.append(','.join(pieces))\n",
    "    \n",
    "for pattern in patterns_simplified:\n",
    "    print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "bda1f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('phrase_examples_filtered_sub10000/non_atomic_phrases.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c2378907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase_length</th>\n",
       "      <th>document_creation_time</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>sentence_startend</th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>phrase_type</th>\n",
       "      <th>phrase_start_end</th>\n",
       "      <th>has_ner_netity</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_sequence</th>\n",
       "      <th>graph</th>\n",
       "      <th>graph_code</th>\n",
       "      <th>graph_code_pos</th>\n",
       "      <th>graph_code_pos_ner_timex</th>\n",
       "      <th>pos_sequence_verb_info</th>\n",
       "      <th>graph_verb_info</th>\n",
       "      <th>graph_code_verb_info</th>\n",
       "      <th>graph_code_pos_verb_info</th>\n",
       "      <th>graph_code_pos_ner_timex_verb_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text(text='neist teede äärtesse')</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-10T00:43</td>\n",
       "      <td>5858921</td>\n",
       "      <td>312319</td>\n",
       "      <td>(0, 226)</td>\n",
       "      <td>aja_EPL</td>\n",
       "      <td>obl_phrase</td>\n",
       "      <td>(84, 104)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>P-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, det),(3, 2, nmod))</td>\n",
       "      <td>(S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))</td>\n",
       "      <td>P-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, det),(3, 2, nmod))</td>\n",
       "      <td>(S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "      <td>9</td>\n",
       "      <td>2024-03-10T00:43</td>\n",
       "      <td>11085184</td>\n",
       "      <td>487500</td>\n",
       "      <td>(227, 375)</td>\n",
       "      <td>aja_pm</td>\n",
       "      <td>nsubj_cop_phrase</td>\n",
       "      <td>(0, 76)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>H-S-S-S-S-S-S-H-H</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7, 0, 8, 9)</td>\n",
       "      <td>((0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))</td>\n",
       "      <td>(S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG-0-0-0-0-0-0,S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))</td>\n",
       "      <td>H-S-S-S-S-S-S-H-H</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 7, 0, 8, 9)</td>\n",
       "      <td>((0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))</td>\n",
       "      <td>(S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG-0-0-0-0-0-0,S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo')</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-10T00:43</td>\n",
       "      <td>11085184</td>\n",
       "      <td>487500</td>\n",
       "      <td>(227, 375)</td>\n",
       "      <td>aja_pm</td>\n",
       "      <td>nmod_phrase</td>\n",
       "      <td>(0, 21)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>H-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, nmod),(3, 2, nmod))</td>\n",
       "      <td>(S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG,S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))</td>\n",
       "      <td>H-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, nmod),(3, 2, nmod))</td>\n",
       "      <td>(S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG,S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna')</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-10T00:43</td>\n",
       "      <td>11085184</td>\n",
       "      <td>487500</td>\n",
       "      <td>(227, 375)</td>\n",
       "      <td>aja_pm</td>\n",
       "      <td>nmod_phrase</td>\n",
       "      <td>(0, 30)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>H-S-S-S</td>\n",
       "      <td>(1, 2, 3, 4, 0)</td>\n",
       "      <td>((0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG-0,S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>H-S-S-S</td>\n",
       "      <td>(1, 2, 3, 4, 0)</td>\n",
       "      <td>((0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG-0,S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli')</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-03-10T00:43</td>\n",
       "      <td>11085184</td>\n",
       "      <td>487500</td>\n",
       "      <td>(227, 375)</td>\n",
       "      <td>aja_pm</td>\n",
       "      <td>nmod_phrase</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>H-S-S-S-S-S</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 0)</td>\n",
       "      <td>((0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))</td>\n",
       "      <td>(S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG-0-0-0,S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))</td>\n",
       "      <td>H-S-S-S-S-S</td>\n",
       "      <td>(1, 2, 3, 4, 5, 6, 0)</td>\n",
       "      <td>((0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))</td>\n",
       "      <td>(S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))</td>\n",
       "      <td>(0-ner_ORG-ner_ORG-0-0-0,S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3051</th>\n",
       "      <td>Text(text='konkureeriva kaabeltelevisooni firma')</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-10T01:35</td>\n",
       "      <td>1526710</td>\n",
       "      <td>61973</td>\n",
       "      <td>(522, 718)</td>\n",
       "      <td>aja_EPL</td>\n",
       "      <td>nmod_phrase</td>\n",
       "      <td>(41, 77)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>A-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3052</th>\n",
       "      <td>Text(text='ka enne 41 aastase mehe arreteerimist')</td>\n",
       "      <td>6</td>\n",
       "      <td>2024-03-10T01:35</td>\n",
       "      <td>3803802</td>\n",
       "      <td>196535</td>\n",
       "      <td>(488, 652)</td>\n",
       "      <td>aja_EPL</td>\n",
       "      <td>obl_phrase</td>\n",
       "      <td>(125, 162)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>D-D-N-A-S-S</td>\n",
       "      <td>(1, 6, 2, 3, 5, 4, 0)</td>\n",
       "      <td>((0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))</td>\n",
       "      <td>(S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))</td>\n",
       "      <td>(0-0-0-0-0-0,S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))</td>\n",
       "      <td>D-D-N-A-S-S</td>\n",
       "      <td>(1, 6, 2, 3, 5, 4, 0)</td>\n",
       "      <td>((0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))</td>\n",
       "      <td>(S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))</td>\n",
       "      <td>(0-0-0-0-0-0,S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3053</th>\n",
       "      <td>Text(text='täiendava motiivi käitumise kooskõlastamiseks')</td>\n",
       "      <td>4</td>\n",
       "      <td>2024-03-10T01:35</td>\n",
       "      <td>8415609</td>\n",
       "      <td>400981</td>\n",
       "      <td>(722528, 722692)</td>\n",
       "      <td>tea</td>\n",
       "      <td>obl_phrase</td>\n",
       "      <td>(95, 140)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A-S-S-S</td>\n",
       "      <td>(1, 2, 3, 4, 0)</td>\n",
       "      <td>((0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(0-0-0-0,S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>A-S-S-S</td>\n",
       "      <td>(1, 2, 3, 4, 0)</td>\n",
       "      <td>((0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "      <td>(0-0-0-0,S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>Text(text='täiendava motiivi käitumise')</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-10T01:35</td>\n",
       "      <td>8415609</td>\n",
       "      <td>400981</td>\n",
       "      <td>(722528, 722692)</td>\n",
       "      <td>tea</td>\n",
       "      <td>nmod_phrase</td>\n",
       "      <td>(95, 122)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>A-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>A-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>Text(text='Iseseisvate kaitsesüsteemide vastavushindamiseks')</td>\n",
       "      <td>3</td>\n",
       "      <td>2024-03-10T01:35</td>\n",
       "      <td>14765840</td>\n",
       "      <td>638709</td>\n",
       "      <td>(20808, 20901)</td>\n",
       "      <td>seadus</td>\n",
       "      <td>obl_phrase</td>\n",
       "      <td>(0, 48)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>H-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>H-S-S</td>\n",
       "      <td>(1, 2, 3, 0)</td>\n",
       "      <td>((0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "      <td>(0-0-0,S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3056 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         phrase  \\\n",
       "0                                                             Text(text='neist teede äärtesse')   \n",
       "1     Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')   \n",
       "2                                                            Text(text='Tartu ülikooli ajaloo')   \n",
       "3                                                   Text(text='Tartu ülikooli ajaloo osakonna')   \n",
       "4                               Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli')   \n",
       "...                                                                                         ...   \n",
       "3051                                          Text(text='konkureeriva kaabeltelevisooni firma')   \n",
       "3052                                         Text(text='ka enne 41 aastase mehe arreteerimist')   \n",
       "3053                                 Text(text='täiendava motiivi käitumise kooskõlastamiseks')   \n",
       "3054                                                   Text(text='täiendava motiivi käitumise')   \n",
       "3055                              Text(text='Iseseisvate kaitsesüsteemide vastavushindamiseks')   \n",
       "\n",
       "      phrase_length document_creation_time  sentence_id  document_id  \\\n",
       "0                 3       2024-03-10T00:43      5858921       312319   \n",
       "1                 9       2024-03-10T00:43     11085184       487500   \n",
       "2                 3       2024-03-10T00:43     11085184       487500   \n",
       "3                 4       2024-03-10T00:43     11085184       487500   \n",
       "4                 6       2024-03-10T00:43     11085184       487500   \n",
       "...             ...                    ...          ...          ...   \n",
       "3051              3       2024-03-10T01:35      1526710        61973   \n",
       "3052              6       2024-03-10T01:35      3803802       196535   \n",
       "3053              4       2024-03-10T01:35      8415609       400981   \n",
       "3054              3       2024-03-10T01:35      8415609       400981   \n",
       "3055              3       2024-03-10T01:35     14765840       638709   \n",
       "\n",
       "     sentence_startend subcorpus       phrase_type phrase_start_end  \\\n",
       "0             (0, 226)   aja_EPL        obl_phrase        (84, 104)   \n",
       "1           (227, 375)    aja_pm  nsubj_cop_phrase          (0, 76)   \n",
       "2           (227, 375)    aja_pm       nmod_phrase          (0, 21)   \n",
       "3           (227, 375)    aja_pm       nmod_phrase          (0, 30)   \n",
       "4           (227, 375)    aja_pm       nmod_phrase          (0, 50)   \n",
       "...                ...       ...               ...              ...   \n",
       "3051        (522, 718)   aja_EPL       nmod_phrase         (41, 77)   \n",
       "3052        (488, 652)   aja_EPL        obl_phrase       (125, 162)   \n",
       "3053  (722528, 722692)       tea        obl_phrase        (95, 140)   \n",
       "3054  (722528, 722692)       tea       nmod_phrase        (95, 122)   \n",
       "3055    (20808, 20901)    seadus        obl_phrase          (0, 48)   \n",
       "\n",
       "      has_ner_netity  ...       pos_sequence                           graph  \\\n",
       "0                  0  ...              P-S-S                    (1, 2, 3, 0)   \n",
       "1                  1  ...  H-S-S-S-S-S-S-H-H  (1, 2, 3, 4, 5, 6, 7, 0, 8, 9)   \n",
       "2                  1  ...              H-S-S                    (1, 2, 3, 0)   \n",
       "3                  1  ...            H-S-S-S                 (1, 2, 3, 4, 0)   \n",
       "4                  1  ...        H-S-S-S-S-S           (1, 2, 3, 4, 5, 6, 0)   \n",
       "...              ...  ...                ...                             ...   \n",
       "3051               0  ...              A-S-S                    (1, 2, 3, 0)   \n",
       "3052               0  ...        D-D-N-A-S-S           (1, 6, 2, 3, 5, 4, 0)   \n",
       "3053               0  ...            A-S-S-S                 (1, 2, 3, 4, 0)   \n",
       "3054               0  ...              A-S-S                    (1, 2, 3, 0)   \n",
       "3055               0  ...              H-S-S                    (1, 2, 3, 0)   \n",
       "\n",
       "                                                                                                                   graph_code  \\\n",
       "0                                                                                     ((0, 3, root),(2, 1, det),(3, 2, nmod))   \n",
       "1     ((0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))   \n",
       "2                                                                                    ((0, 3, root),(2, 1, nmod),(3, 2, nmod))   \n",
       "3                                                                       ((0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))   \n",
       "4                                             ((0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))   \n",
       "...                                                                                                                       ...   \n",
       "3051                                                                                  ((0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3052                                      ((0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))   \n",
       "3053                                                                     ((0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))   \n",
       "3054                                                                                  ((0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3055                                                                                  ((0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "\n",
       "                                                                                                                                 graph_code_pos  \\\n",
       "0                                                                                                 (S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))   \n",
       "1     (S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))   \n",
       "2                                                                                                (S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))   \n",
       "3                                                                                 (S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))   \n",
       "4                                                   (S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))   \n",
       "...                                                                                                                                         ...   \n",
       "3051                                                                                              (S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3052                                            (S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))   \n",
       "3053                                                                               (S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))   \n",
       "3054                                                                                              (S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3055                                                                                              (S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "\n",
       "                                                                                                                                                     graph_code_pos_ner_timex  \\\n",
       "0                                                                                                                         (0-0-0,S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))   \n",
       "1     (0-ner_ORG-ner_ORG-0-0-0-0-0-0,S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))   \n",
       "2                                                                                                            (0-ner_ORG-ner_ORG,S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))   \n",
       "3                                                                                           (0-ner_ORG-ner_ORG-0,S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))   \n",
       "4                                                         (0-ner_ORG-ner_ORG-0-0-0,S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))   \n",
       "...                                                                                                                                                                       ...   \n",
       "3051                                                                                                                      (0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3052                                                              (0-0-0-0-0-0,S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))   \n",
       "3053                                                                                                     (0-0-0-0,S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))   \n",
       "3054                                                                                                                      (0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3055                                                                                                                      (0-0-0,S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "\n",
       "     pos_sequence_verb_info                 graph_verb_info  \\\n",
       "0                     P-S-S                    (1, 2, 3, 0)   \n",
       "1         H-S-S-S-S-S-S-H-H  (1, 2, 3, 4, 5, 6, 7, 0, 8, 9)   \n",
       "2                     H-S-S                    (1, 2, 3, 0)   \n",
       "3                   H-S-S-S                 (1, 2, 3, 4, 0)   \n",
       "4               H-S-S-S-S-S           (1, 2, 3, 4, 5, 6, 0)   \n",
       "...                     ...                             ...   \n",
       "3051                  A-S-S                    (1, 2, 3, 0)   \n",
       "3052            D-D-N-A-S-S           (1, 6, 2, 3, 5, 4, 0)   \n",
       "3053                A-S-S-S                 (1, 2, 3, 4, 0)   \n",
       "3054                  A-S-S                    (1, 2, 3, 0)   \n",
       "3055                  H-S-S                    (1, 2, 3, 0)   \n",
       "\n",
       "                                                                                                         graph_code_verb_info  \\\n",
       "0                                                                                     ((0, 3, root),(2, 1, det),(3, 2, nmod))   \n",
       "1     ((0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))   \n",
       "2                                                                                    ((0, 3, root),(2, 1, nmod),(3, 2, nmod))   \n",
       "3                                                                       ((0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))   \n",
       "4                                             ((0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))   \n",
       "...                                                                                                                       ...   \n",
       "3051                                                                                  ((0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3052                                      ((0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))   \n",
       "3053                                                                     ((0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))   \n",
       "3054                                                                                  ((0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3055                                                                                  ((0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "\n",
       "                                                                                                                       graph_code_pos_verb_info  \\\n",
       "0                                                                                                 (S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))   \n",
       "1     (S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))   \n",
       "2                                                                                                (S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))   \n",
       "3                                                                                 (S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))   \n",
       "4                                                   (S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))   \n",
       "...                                                                                                                                         ...   \n",
       "3051                                                                                              (S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3052                                            (S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))   \n",
       "3053                                                                               (S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))   \n",
       "3054                                                                                              (S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "3055                                                                                              (S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))   \n",
       "\n",
       "                                                                                                                                           graph_code_pos_ner_timex_verb_info  \n",
       "0                                                                                                                         (0-0-0,S-P-S,(0, 3, root),(2, 1, det),(3, 2, nmod))  \n",
       "1     (0-ner_ORG-ner_ORG-0-0-0-0-0-0,S-H-S-S-S-S-S-H-H,(0, 7, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod),(7, 6, nmod),(7, 8, appos),(8, 9, flat))  \n",
       "2                                                                                                            (0-ner_ORG-ner_ORG,S-H-S,(0, 3, root),(2, 1, nmod),(3, 2, nmod))  \n",
       "3                                                                                           (0-ner_ORG-ner_ORG-0,S-H-S-S,(0, 4, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod))  \n",
       "4                                                         (0-ner_ORG-ner_ORG-0-0-0,S-H-S-S-S-S,(0, 6, root),(2, 1, nmod),(3, 2, nmod),(4, 3, nmod),(5, 4, nmod),(6, 5, nmod))  \n",
       "...                                                                                                                                                                       ...  \n",
       "3051                                                                                                                      (0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))  \n",
       "3052                                                              (0-0-0-0-0-0,S-N-S-A-D-D,(0, 6, root),(5, 3, nummod),(5, 4, amod),(6, 1, advmod),(6, 2, case),(6, 5, nmod))  \n",
       "3053                                                                                                     (0-0-0-0,S-A-S-S,(0, 4, root),(2, 1, acl),(3, 2, nmod),(4, 3, nmod))  \n",
       "3054                                                                                                                      (0-0-0,S-A-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))  \n",
       "3055                                                                                                                      (0-0-0,S-H-S,(0, 3, root),(2, 1, acl),(3, 2, nmod))  \n",
       "\n",
       "[3056 rows x 21 columns]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "6e3a307a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = None\n",
    "for idx, row in df.iterrows():\n",
    "    test = row['phrase']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "5f757faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>id, lemma, upostag, xpostag, feats, head, deprel, deps, misc, parent_span, children</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "#T_a8c09_row2_col10 {\n",
       "  opacity: 20%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a8c09\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_a8c09_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_a8c09_level0_col1\" class=\"col_heading level0 col1\" >id</th>\n",
       "      <th id=\"T_a8c09_level0_col2\" class=\"col_heading level0 col2\" >lemma</th>\n",
       "      <th id=\"T_a8c09_level0_col3\" class=\"col_heading level0 col3\" >upostag</th>\n",
       "      <th id=\"T_a8c09_level0_col4\" class=\"col_heading level0 col4\" >xpostag</th>\n",
       "      <th id=\"T_a8c09_level0_col5\" class=\"col_heading level0 col5\" >feats</th>\n",
       "      <th id=\"T_a8c09_level0_col6\" class=\"col_heading level0 col6\" >head</th>\n",
       "      <th id=\"T_a8c09_level0_col7\" class=\"col_heading level0 col7\" >deprel</th>\n",
       "      <th id=\"T_a8c09_level0_col8\" class=\"col_heading level0 col8\" >deps</th>\n",
       "      <th id=\"T_a8c09_level0_col9\" class=\"col_heading level0 col9\" >misc</th>\n",
       "      <th id=\"T_a8c09_level0_col10\" class=\"col_heading level0 col10\" >parent_span</th>\n",
       "      <th id=\"T_a8c09_level0_col11\" class=\"col_heading level0 col11\" >children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_a8c09_row0_col0\" class=\"data row0 col0\" >neist</td>\n",
       "      <td id=\"T_a8c09_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_a8c09_row0_col2\" class=\"data row0 col2\" >see</td>\n",
       "      <td id=\"T_a8c09_row0_col3\" class=\"data row0 col3\" >P</td>\n",
       "      <td id=\"T_a8c09_row0_col4\" class=\"data row0 col4\" >P</td>\n",
       "      <td id=\"T_a8c09_row0_col5\" class=\"data row0 col5\" >OrderedDict([('pl', 'pl'), ('el', 'el')])</td>\n",
       "      <td id=\"T_a8c09_row0_col6\" class=\"data row0 col6\" >2</td>\n",
       "      <td id=\"T_a8c09_row0_col7\" class=\"data row0 col7\" >det</td>\n",
       "      <td id=\"T_a8c09_row0_col8\" class=\"data row0 col8\" >_</td>\n",
       "      <td id=\"T_a8c09_row0_col9\" class=\"data row0 col9\" >_</td>\n",
       "      <td id=\"T_a8c09_row0_col10\" class=\"data row0 col10\" >Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats' ..., type: <class 'estnltk_core.layer.span.Span'></td>\n",
       "      <td id=\"T_a8c09_row0_col11\" class=\"data row0 col11\" >()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a8c09_row1_col0\" class=\"data row1 col0\" >teede</td>\n",
       "      <td id=\"T_a8c09_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_a8c09_row1_col2\" class=\"data row1 col2\" >tee</td>\n",
       "      <td id=\"T_a8c09_row1_col3\" class=\"data row1 col3\" >S</td>\n",
       "      <td id=\"T_a8c09_row1_col4\" class=\"data row1 col4\" >S</td>\n",
       "      <td id=\"T_a8c09_row1_col5\" class=\"data row1 col5\" >OrderedDict([('pl', 'pl'), ('g', 'g')])</td>\n",
       "      <td id=\"T_a8c09_row1_col6\" class=\"data row1 col6\" >3</td>\n",
       "      <td id=\"T_a8c09_row1_col7\" class=\"data row1 col7\" >nmod</td>\n",
       "      <td id=\"T_a8c09_row1_col8\" class=\"data row1 col8\" >_</td>\n",
       "      <td id=\"T_a8c09_row1_col9\" class=\"data row1 col9\" >_</td>\n",
       "      <td id=\"T_a8c09_row1_col10\" class=\"data row1 col10\" >Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'fea ..., type: <class 'estnltk_core.layer.span.Span'></td>\n",
       "      <td id=\"T_a8c09_row1_col11\" class=\"data row1 col11\" >(\"Span('neist', [{'id': 1, 'lemma': 'see', 'upostag': 'P', 'xpostag': 'P', 'feat ..., type: <class 'tuple'>, length: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_a8c09_row2_col0\" class=\"data row2 col0\" >äärtesse</td>\n",
       "      <td id=\"T_a8c09_row2_col1\" class=\"data row2 col1\" >3</td>\n",
       "      <td id=\"T_a8c09_row2_col2\" class=\"data row2 col2\" >äär</td>\n",
       "      <td id=\"T_a8c09_row2_col3\" class=\"data row2 col3\" >S</td>\n",
       "      <td id=\"T_a8c09_row2_col4\" class=\"data row2 col4\" >S</td>\n",
       "      <td id=\"T_a8c09_row2_col5\" class=\"data row2 col5\" >OrderedDict([('pl', 'pl'), ('ill', 'ill')])</td>\n",
       "      <td id=\"T_a8c09_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_a8c09_row2_col7\" class=\"data row2 col7\" >root</td>\n",
       "      <td id=\"T_a8c09_row2_col8\" class=\"data row2 col8\" >_</td>\n",
       "      <td id=\"T_a8c09_row2_col9\" class=\"data row2 col9\" >_</td>\n",
       "      <td id=\"T_a8c09_row2_col10\" class=\"data row2 col10\" >None</td>\n",
       "      <td id=\"T_a8c09_row2_col11\" class=\"data row2 col11\" >(\"Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feat ..., type: <class 'tuple'>, length: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='stanza_syntax', attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc', 'parent_span', 'children'), spans=SL[Span('neist', [{'id': 1, 'lemma': 'see', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('pl', 'pl'), ('el', 'el')]), 'head': 2, 'deprel': 'det', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]),\n",
       "Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]),\n",
       "Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('ill', 'ill')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])])"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.stanza_syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "c092fb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ner_timex(text_obj, stanza_word):\n",
    "    ner = None\n",
    "    nertag = None\n",
    "    if len(text_obj.ner) > 0:\n",
    "        word = text_obj.words.get(stanza_word)\n",
    "        for n in text_obj.ner:\n",
    "            for part in n:\n",
    "                if part==word:\n",
    "                    ner=word\n",
    "                    nertag=n.nertag\n",
    "    timex = text_obj.timexes.get(stanza_word)\n",
    "    if ner:\n",
    "        return nertag\n",
    "    if timex:\n",
    "        return 'TIMEX'\n",
    "    return 'OTHER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f8546f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_POS(word):\n",
    "    #pos_list = word.morph_analysis['partofspeech']\n",
    "    infinite_verb_forms = ['da', 'des', 'ma', 'maks', 'mas', 'mast', 'mata', 'nud', 'tav', 'tud', 'v']\n",
    "    # if POS is ambiguous, only unique tags are kept, e.g. ['V', 'A', 'A'] -> ['V', 'A']\n",
    "    pos_list = []\n",
    "    for i in range(len(word.morph_analysis['partofspeech'])):\n",
    "        if word.morph_analysis['partofspeech'][i] == 'V':\n",
    "            if word.morph_analysis['form'][i] in infinite_verb_forms:\n",
    "                pos_list.append('V_inf')\n",
    "            elif word.form[i] == 'neg':\n",
    "                pos_list.append('V_neg')\n",
    "            else:\n",
    "                pos_list.append('V_fin')\n",
    "        else:\n",
    "            pos_list.append(word.morph_analysis['partofspeech'][i])\n",
    "    \n",
    "    if len(pos_list) > 1:\n",
    "        char_unique = [char for indx, char in enumerate(pos_list) if char not in pos_list[:indx]]\n",
    "        if len(char_unique) < 2:\n",
    "            return char_unique[0]\n",
    "        return '|'.join(char_unique)\n",
    "    return pos_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abff2379",
   "metadata": {},
   "source": [
    "Naiivne lähenemine: vaatab vaid variante, kus liikmed paiknevad järjest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c5cb0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_matches_found = []\n",
    "\n",
    "for i in range(len(test.stanza_syntax)-1):\n",
    "    pattern_found = []\n",
    "    ner_timex = get_ner_timex(test, test.stanza_syntax[i])\n",
    "    pos = get_unique_POS(test.stanza_syntax[i])\n",
    "    pattern_found.append(f'{test.stanza_syntax[i].id} {ner_timex} {test.stanza_syntax[i].head} {test.stanza_syntax[i].deprel} {pos}')\n",
    "    for j in range(i+1, len(test.stanza_syntax)):\n",
    "        ner_timex = get_ner_timex(test, test.stanza_syntax[j])\n",
    "        pos = get_unique_POS(test.stanza_syntax[j])\n",
    "        pattern_found.append(f'{test.stanza_syntax[j].id} {ner_timex} {test.stanza_syntax[j].head} {test.stanza_syntax[j].deprel} {pos}')\n",
    "        if ','.join(pattern_found) in patterns:\n",
    "            pattern_matches_found += ','.join(pattern_found)\n",
    "        if j == len(test.stanza_syntax):\n",
    "            pattern_found = []\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d8a2c0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ORG 1 appos H,3 OTHER 2 flat S\n"
     ]
    }
   ],
   "source": [
    "print(','.join(pattern_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1de3541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = None\n",
    "for idx, row in df.iterrows():\n",
    "    if idx == 0:\n",
    "        test2 = row['phrase']\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "14ccdfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>id, lemma, upostag, xpostag, feats, head, deprel, deps, misc, parent_span, children</td>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<style type=\"text/css\">\n",
       "#T_84f7e_row2_col10 {\n",
       "  opacity: 20%;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_84f7e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_84f7e_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_84f7e_level0_col1\" class=\"col_heading level0 col1\" >id</th>\n",
       "      <th id=\"T_84f7e_level0_col2\" class=\"col_heading level0 col2\" >lemma</th>\n",
       "      <th id=\"T_84f7e_level0_col3\" class=\"col_heading level0 col3\" >upostag</th>\n",
       "      <th id=\"T_84f7e_level0_col4\" class=\"col_heading level0 col4\" >xpostag</th>\n",
       "      <th id=\"T_84f7e_level0_col5\" class=\"col_heading level0 col5\" >feats</th>\n",
       "      <th id=\"T_84f7e_level0_col6\" class=\"col_heading level0 col6\" >head</th>\n",
       "      <th id=\"T_84f7e_level0_col7\" class=\"col_heading level0 col7\" >deprel</th>\n",
       "      <th id=\"T_84f7e_level0_col8\" class=\"col_heading level0 col8\" >deps</th>\n",
       "      <th id=\"T_84f7e_level0_col9\" class=\"col_heading level0 col9\" >misc</th>\n",
       "      <th id=\"T_84f7e_level0_col10\" class=\"col_heading level0 col10\" >parent_span</th>\n",
       "      <th id=\"T_84f7e_level0_col11\" class=\"col_heading level0 col11\" >children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_84f7e_row0_col0\" class=\"data row0 col0\" >neist</td>\n",
       "      <td id=\"T_84f7e_row0_col1\" class=\"data row0 col1\" >1</td>\n",
       "      <td id=\"T_84f7e_row0_col2\" class=\"data row0 col2\" >see</td>\n",
       "      <td id=\"T_84f7e_row0_col3\" class=\"data row0 col3\" >P</td>\n",
       "      <td id=\"T_84f7e_row0_col4\" class=\"data row0 col4\" >P</td>\n",
       "      <td id=\"T_84f7e_row0_col5\" class=\"data row0 col5\" >OrderedDict([('pl', 'pl'), ('el', 'el')])</td>\n",
       "      <td id=\"T_84f7e_row0_col6\" class=\"data row0 col6\" >2</td>\n",
       "      <td id=\"T_84f7e_row0_col7\" class=\"data row0 col7\" >det</td>\n",
       "      <td id=\"T_84f7e_row0_col8\" class=\"data row0 col8\" >_</td>\n",
       "      <td id=\"T_84f7e_row0_col9\" class=\"data row0 col9\" >_</td>\n",
       "      <td id=\"T_84f7e_row0_col10\" class=\"data row0 col10\" >Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats' ..., type: <class 'estnltk_core.layer.span.Span'></td>\n",
       "      <td id=\"T_84f7e_row0_col11\" class=\"data row0 col11\" >()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_84f7e_row1_col0\" class=\"data row1 col0\" >teede</td>\n",
       "      <td id=\"T_84f7e_row1_col1\" class=\"data row1 col1\" >2</td>\n",
       "      <td id=\"T_84f7e_row1_col2\" class=\"data row1 col2\" >tee</td>\n",
       "      <td id=\"T_84f7e_row1_col3\" class=\"data row1 col3\" >S</td>\n",
       "      <td id=\"T_84f7e_row1_col4\" class=\"data row1 col4\" >S</td>\n",
       "      <td id=\"T_84f7e_row1_col5\" class=\"data row1 col5\" >OrderedDict([('pl', 'pl'), ('g', 'g')])</td>\n",
       "      <td id=\"T_84f7e_row1_col6\" class=\"data row1 col6\" >3</td>\n",
       "      <td id=\"T_84f7e_row1_col7\" class=\"data row1 col7\" >nmod</td>\n",
       "      <td id=\"T_84f7e_row1_col8\" class=\"data row1 col8\" >_</td>\n",
       "      <td id=\"T_84f7e_row1_col9\" class=\"data row1 col9\" >_</td>\n",
       "      <td id=\"T_84f7e_row1_col10\" class=\"data row1 col10\" >Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'fea ..., type: <class 'estnltk_core.layer.span.Span'></td>\n",
       "      <td id=\"T_84f7e_row1_col11\" class=\"data row1 col11\" >(\"Span('neist', [{'id': 1, 'lemma': 'see', 'upostag': 'P', 'xpostag': 'P', 'feat ..., type: <class 'tuple'>, length: 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_84f7e_row2_col0\" class=\"data row2 col0\" >äärtesse</td>\n",
       "      <td id=\"T_84f7e_row2_col1\" class=\"data row2 col1\" >3</td>\n",
       "      <td id=\"T_84f7e_row2_col2\" class=\"data row2 col2\" >äär</td>\n",
       "      <td id=\"T_84f7e_row2_col3\" class=\"data row2 col3\" >S</td>\n",
       "      <td id=\"T_84f7e_row2_col4\" class=\"data row2 col4\" >S</td>\n",
       "      <td id=\"T_84f7e_row2_col5\" class=\"data row2 col5\" >OrderedDict([('pl', 'pl'), ('ill', 'ill')])</td>\n",
       "      <td id=\"T_84f7e_row2_col6\" class=\"data row2 col6\" >0</td>\n",
       "      <td id=\"T_84f7e_row2_col7\" class=\"data row2 col7\" >root</td>\n",
       "      <td id=\"T_84f7e_row2_col8\" class=\"data row2 col8\" >_</td>\n",
       "      <td id=\"T_84f7e_row2_col9\" class=\"data row2 col9\" >_</td>\n",
       "      <td id=\"T_84f7e_row2_col10\" class=\"data row2 col10\" >None</td>\n",
       "      <td id=\"T_84f7e_row2_col11\" class=\"data row2 col11\" >(\"Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feat ..., type: <class 'tuple'>, length: 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "Layer(name='stanza_syntax', attributes=('id', 'lemma', 'upostag', 'xpostag', 'feats', 'head', 'deprel', 'deps', 'misc', 'parent_span', 'children'), spans=SL[Span('neist', [{'id': 1, 'lemma': 'see', 'upostag': 'P', 'xpostag': 'P', 'feats': OrderedDict([('pl', 'pl'), ('el', 'el')]), 'head': 2, 'deprel': 'det', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]),\n",
       "Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]),\n",
       "Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('ill', 'ill')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.stanza_syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6d49ce4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 2 det P', '2 0 root S']\n",
      "1 2 det P,2 0 root S\n",
      "False\n",
      "['1 2 det P', '2 3 nmod S', '3 0 root S']\n",
      "1 2 det P,2 3 nmod S,3 0 root S\n",
      "False\n",
      "['1 2 nmod S', '2 0 root S']\n",
      "1 2 nmod S,2 0 root S\n",
      "True\n",
      "[['1 2 nmod S,2 0 root S', 'teede äärtesse', [Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('ill', 'ill')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]]]\n"
     ]
    }
   ],
   "source": [
    "# getting patterns without ner/timex/other\n",
    "pattern_matches_found = []\n",
    "\n",
    "for i in range(len(test2.stanza_syntax) - 1):\n",
    "    pattern_members = []\n",
    "    ids = []\n",
    "\n",
    "    pattern_members.append(test2.stanza_syntax[i])\n",
    "    #ner_timex = get_ner_timex(test2, test2.stanza_syntax[i])\n",
    "    ids.append([test2.stanza_syntax[i].id, test2.stanza_syntax[i].head])\n",
    "\n",
    "    for j in range(i + 1, len(test2.stanza_syntax)):\n",
    "        pattern_found = []\n",
    "        current_members = []\n",
    "        for k in range(len(pattern_members)):\n",
    "            #print(member)\n",
    "            #print(test2.stanza_syntax[j])\n",
    "            if test2.stanza_syntax[j] in pattern_members[k].children or pattern_members[k] in test2.stanza_syntax[j].children or test2.stanza_syntax[j].parent != None and test2.stanza_syntax[j].parent == pattern_members[k].parent:\n",
    "                current_members.append(pattern_members[k])\n",
    "                current_members.append(test2.stanza_syntax[j])\n",
    "                pattern_members.append(test2.stanza_syntax[j])\n",
    "                #ner_timex = get_ner_timex(test2, test2.stanza_syntax[j])\n",
    "                ids.append([test2.stanza_syntax[j].id, test2.stanza_syntax[j].head])\n",
    "        \n",
    "        ids_for_pattern = copy.deepcopy(ids)\n",
    "        for l in range(len(ids_for_pattern)):\n",
    "            temp = ids_for_pattern[l][0]\n",
    "            ids_for_pattern[l][0] = l+1\n",
    "            for m in range(len(ids)):\n",
    "                if ids[m][1] == temp:\n",
    "                    ids_for_pattern[m][1] = ids_for_pattern[l][0]\n",
    "            \n",
    "        word_ids = [word_id[0] for word_id in ids_for_pattern]\n",
    "        for l in range(len(ids_for_pattern)):\n",
    "            if ids_for_pattern[l][0] == ids_for_pattern[l][1]:\n",
    "                ids_for_pattern[l][1] = 0\n",
    "            elif ids_for_pattern[l][1] not in word_ids:\n",
    "                ids_for_pattern[l][1] = 0\n",
    "            \n",
    "        for l in range(len(pattern_members)):\n",
    "            deprel = pattern_members[l].deprel\n",
    "            if ids_for_pattern[l][1] == 0 and deprel != 'root':\n",
    "                deprel = 'root'\n",
    "            pattern_found.append([str(ids_for_pattern[l][0]), str(ids_for_pattern[l][1]), deprel, get_unique_POS(pattern_members[l])])\n",
    "        \n",
    "        sub_pattern = [\" \".join(word_info) for word_info in pattern_found]\n",
    "        print(sub_pattern)\n",
    "        print(\",\".join(sub_pattern))\n",
    "        print(\",\".join(sub_pattern) in patterns_simplified)\n",
    "        if \",\".join(sub_pattern) in patterns_simplified:\n",
    "            pattern_matches_found.append([\",\".join(sub_pattern), \" \".join([member.text for member in pattern_members]), [member for member in pattern_members]])\n",
    "\n",
    "        if j == len(test2.stanza_syntax) - 1:\n",
    "            pattern_members = []\n",
    "            ids = []\n",
    "            break\n",
    "\n",
    "print(pattern_matches_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "ebfd75c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 OTHER 2 det P', '2 OTHER 0 root S']\n",
      "1 OTHER 2 det P,2 OTHER 0 root S\n",
      "False\n",
      "['1 OTHER 2 det P', '2 OTHER 3 nmod S', '3 OTHER 0 root S']\n",
      "1 OTHER 2 det P,2 OTHER 3 nmod S,3 OTHER 0 root S\n",
      "False\n",
      "['1 OTHER 2 nmod S', '2 OTHER 0 root S']\n",
      "1 OTHER 2 nmod S,2 OTHER 0 root S\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# getting patterns with ner/timex/other\n",
    "pattern_matches_found = []\n",
    "\n",
    "for i in range(len(test2.stanza_syntax) - 1):\n",
    "    pattern_members = []\n",
    "    ner_timex = []\n",
    "    ids = []\n",
    "\n",
    "    pattern_members.append(test2.stanza_syntax[i])\n",
    "    ner_timex.append(get_ner_timex(test2, test2.stanza_syntax[i]))\n",
    "    ids.append([test2.stanza_syntax[i].id, test2.stanza_syntax[i].head])\n",
    "\n",
    "    for j in range(i + 1, len(test2.stanza_syntax)):\n",
    "        pattern_found = []\n",
    "        current_members = []\n",
    "        for k in range(len(pattern_members)):\n",
    "            #print(member)\n",
    "            #print(test2.stanza_syntax[j])\n",
    "            if test2.stanza_syntax[j] in pattern_members[k].children or pattern_members[k] in test2.stanza_syntax[j].children or test2.stanza_syntax[j].parent != None and test2.stanza_syntax[j].parent == pattern_members[k].parent:\n",
    "                current_members.append(pattern_members[k])\n",
    "                current_members.append(test2.stanza_syntax[j])\n",
    "                pattern_members.append(test2.stanza_syntax[j])\n",
    "                ner_timex.append(get_ner_timex(test2, test2.stanza_syntax[j]))\n",
    "                ids.append([test2.stanza_syntax[j].id, test2.stanza_syntax[j].head])\n",
    "        \n",
    "        ids_for_pattern = copy.deepcopy(ids)\n",
    "        for l in range(len(ids_for_pattern)):\n",
    "            temp = ids_for_pattern[l][0]\n",
    "            ids_for_pattern[l][0] = l+1\n",
    "            for m in range(len(ids)):\n",
    "                if ids[m][1] == temp:\n",
    "                    ids_for_pattern[m][1] = ids_for_pattern[l][0]\n",
    "            \n",
    "        word_ids = [word_id[0] for word_id in ids_for_pattern]\n",
    "        for l in range(len(ids_for_pattern)):\n",
    "            if ids_for_pattern[l][0] == ids_for_pattern[l][1]:\n",
    "                ids_for_pattern[l][1] = 0\n",
    "            elif ids_for_pattern[l][1] not in word_ids:\n",
    "                ids_for_pattern[l][1] = 0\n",
    "            \n",
    "        for l in range(len(pattern_members)):\n",
    "            deprel = pattern_members[l].deprel\n",
    "            if ids_for_pattern[l][1] == 0 and deprel != 'root':\n",
    "                deprel = 'root'\n",
    "            pattern_found.append([str(ids_for_pattern[l][0]), ner_timex[l], str(ids_for_pattern[l][1]), deprel, get_unique_POS(pattern_members[l])])\n",
    "        \n",
    "        sub_pattern = [\" \".join(word_info) for word_info in pattern_found]\n",
    "        print(sub_pattern)\n",
    "        print(\",\".join(sub_pattern))\n",
    "        print(\",\".join(sub_pattern) in patterns_simplified)\n",
    "        if \",\".join(sub_pattern) in patterns_simplified:\n",
    "            pattern_matches_found.append(\",\".join(sub_pattern))\n",
    "\n",
    "        if j == len(test2.stanza_syntax) - 1:\n",
    "            pattern_members = []\n",
    "            ids = []\n",
    "            break\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10be655f",
   "metadata": {},
   "source": [
    "### On more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "6260e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_patterns(phrase):\n",
    "    pattern_matches_found = []\n",
    "    \n",
    "    for i in range(len(phrase.stanza_syntax) - 1):\n",
    "        pattern_members = []\n",
    "        ids = []\n",
    "\n",
    "        pattern_members.append(phrase.stanza_syntax[i])\n",
    "        #ner_timex = get_ner_timex(phrase, phrase.stanza_syntax[i])\n",
    "        ids.append([phrase.stanza_syntax[i].id, phrase.stanza_syntax[i].head])\n",
    "\n",
    "        for j in range(i + 1, len(phrase.stanza_syntax)):\n",
    "            pattern_found = []\n",
    "            for k in range(len(pattern_members)):\n",
    "                if phrase.stanza_syntax[j] in pattern_members[k].children or pattern_members[k] in phrase.stanza_syntax[j].children or phrase.stanza_syntax[j].parent != None and phrase.stanza_syntax[j].parent == pattern_members[k].parent:\n",
    "                    pattern_members.append(phrase.stanza_syntax[j])\n",
    "                    #ner_timex = get_ner_timex(phrase, phrase.stanza_syntax[j])\n",
    "                    ids.append([phrase.stanza_syntax[j].id, phrase.stanza_syntax[j].head])\n",
    "        \n",
    "            ids_for_pattern = copy.deepcopy(ids)\n",
    "            for l in range(len(ids_for_pattern)):\n",
    "                temp = ids_for_pattern[l][0]\n",
    "                ids_for_pattern[l][0] = l+1\n",
    "                for m in range(len(ids)):\n",
    "                    if ids[m][1] == temp:\n",
    "                        ids_for_pattern[m][1] = ids_for_pattern[l][0]\n",
    "            \n",
    "            word_ids = [word_id[0] for word_id in ids_for_pattern]\n",
    "            for l in range(len(ids_for_pattern)):\n",
    "                if ids_for_pattern[l][0] == ids_for_pattern[l][1]:\n",
    "                    ids_for_pattern[l][1] = 0\n",
    "                elif ids_for_pattern[l][1] not in word_ids:\n",
    "                    ids_for_pattern[l][1] = 0\n",
    "            \n",
    "            for l in range(len(pattern_members)):\n",
    "                deprel = pattern_members[l].deprel\n",
    "                if ids_for_pattern[l][1] == 0 and deprel != 'root':\n",
    "                    deprel = 'root'\n",
    "                pattern_found.append([str(ids_for_pattern[l][0]), str(ids_for_pattern[l][1]), deprel, get_unique_POS(pattern_members[l])])\n",
    "                    \n",
    "            sub_pattern = [\" \".join(word_info) for word_info in pattern_found]\n",
    "            if \",\".join(sub_pattern) in patterns_simplified:\n",
    "                pattern_matches_found.append([\",\".join(sub_pattern), \" \".join([member.text for member in pattern_members]), [member for member in pattern_members]])\n",
    "\n",
    "            if j == len(test2.stanza_syntax) - 1:\n",
    "                pattern_members = []\n",
    "                ids = []\n",
    "                break             \n",
    "                    \n",
    "    return pattern_matches_found\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_patterns_ner_timex(phrase):\n",
    "pattern_matches_found = []\n",
    "\n",
    "for i in range(len(test2.stanza_syntax) - 1):\n",
    "    pattern_members = []\n",
    "    ner_timex = []\n",
    "    ids = []\n",
    "\n",
    "    pattern_members.append(test2.stanza_syntax[i])\n",
    "    ner_timex.append(get_ner_timex(test2, test2.stanza_syntax[i]))\n",
    "    ids.append([test2.stanza_syntax[i].id, test2.stanza_syntax[i].head])\n",
    "\n",
    "    for j in range(i + 1, len(test2.stanza_syntax)):\n",
    "        pattern_found = []\n",
    "        current_members = []\n",
    "        for k in range(len(pattern_members)):\n",
    "            #print(member)\n",
    "            #print(test2.stanza_syntax[j])\n",
    "            if test2.stanza_syntax[j] in pattern_members[k].children or pattern_members[k] in test2.stanza_syntax[j].children or test2.stanza_syntax[j].parent != None and test2.stanza_syntax[j].parent == pattern_members[k].parent:\n",
    "                current_members.append(pattern_members[k])\n",
    "                current_members.append(test2.stanza_syntax[j])\n",
    "                pattern_members.append(test2.stanza_syntax[j])\n",
    "                ner_timex.append(get_ner_timex(test2, test2.stanza_syntax[j]))\n",
    "                ids.append([test2.stanza_syntax[j].id, test2.stanza_syntax[j].head])\n",
    "        \n",
    "        ids_for_pattern = copy.deepcopy(ids)\n",
    "        for l in range(len(ids_for_pattern)):\n",
    "            temp = ids_for_pattern[l][0]\n",
    "            ids_for_pattern[l][0] = l+1\n",
    "            for m in range(len(ids)):\n",
    "                if ids[m][1] == temp:\n",
    "                    ids_for_pattern[m][1] = ids_for_pattern[l][0]\n",
    "            \n",
    "        word_ids = [word_id[0] for word_id in ids_for_pattern]\n",
    "        for l in range(len(ids_for_pattern)):\n",
    "            if ids_for_pattern[l][0] == ids_for_pattern[l][1]:\n",
    "                ids_for_pattern[l][1] = 0\n",
    "            elif ids_for_pattern[l][1] not in word_ids:\n",
    "                ids_for_pattern[l][1] = 0\n",
    "            \n",
    "        for l in range(len(pattern_members)):\n",
    "            deprel = pattern_members[l].deprel\n",
    "            if ids_for_pattern[l][1] == 0 and deprel != 'root':\n",
    "                deprel = 'root'\n",
    "            pattern_found.append([str(ids_for_pattern[l][0]), ner_timex[l], str(ids_for_pattern[l][1]), deprel, get_unique_POS(pattern_members[l])])\n",
    "        \n",
    "        sub_pattern = [\" \".join(word_info) for word_info in pattern_found]\n",
    "        print(sub_pattern)\n",
    "        print(\",\".join(sub_pattern))\n",
    "        print(\",\".join(sub_pattern) in patterns_simplified)\n",
    "        if \",\".join(sub_pattern) in patterns_simplified:\n",
    "            pattern_matches_found.append(\",\".join(sub_pattern))\n",
    "\n",
    "        if j == len(test2.stanza_syntax) - 1:\n",
    "            pattern_members = []\n",
    "            ids = []\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "12dbf9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# searching for matches from both atomic and non-atomic phrases\n",
    "df_non_atomic = pd.read_pickle('phrase_examples_filtered_sub10000/non_atomic_phrases.pkl')\n",
    "df_atomic = pd.read_pickle('phrase_examples_filtered_sub10000/atomic_phrases.pkl')\n",
    "concatenated = pd.concat([df_non_atomic, df_atomic])\n",
    "\n",
    "correct_matches = {'pattern': [], 'phrase_text': [], 'phrase_spans': [], 'parent_phrase': []}\n",
    "\n",
    "for idx, row in concatenated.iterrows():\n",
    "    matches = find_patterns(row['phrase'])\n",
    "    if len(matches) > 0:\n",
    "        for match in matches:\n",
    "            correct_matches['pattern'].append(match[0])\n",
    "            correct_matches['phrase_text'].append(match[1])\n",
    "            correct_matches['phrase_spans'].append(match[2])\n",
    "            correct_matches['parent_phrase'].append(row['phrase'])\n",
    "            \n",
    "matches_df = pd.DataFrame(correct_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "9a2f68e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>phrase_text</th>\n",
       "      <th>phrase_spans</th>\n",
       "      <th>parent_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>teede äärtesse</td>\n",
       "      <td>[Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('ill', 'ill')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='neist teede äärtesse')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>Tartu ülikooli</td>\n",
       "      <td>[Span('Tartu', [{'id': 1, 'lemma': 'Tartu', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>ülikooli ajaloo</td>\n",
       "      <td>[Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>ajaloo osakonna</td>\n",
       "      <td>[Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>osakonna üldajaloo</td>\n",
       "      <td>[Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('üldajaloo', [{'id': 5, 'lemma': 'üldajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 6, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10282</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>normi ettekirjutusega</td>\n",
       "      <td>[Span('normi', [{'id': 1, 'lemma': 'norm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('ettekirjutusega', [{'id': 2, 'lemma': 'ettekirjutus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('kom', 'kom')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='normi ettekirjutusega')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>õiguse subjekt</td>\n",
       "      <td>[Span('õiguse', [{'id': 1, 'lemma': 'õigus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('subjekt', [{'id': 2, 'lemma': 'subjekt', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='õiguse subjekt')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10284</th>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>Pekingi slummis</td>\n",
       "      <td>[Span('Pekingi', [{'id': 1, 'lemma': 'Peking', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('slummis', [{'id': 2, 'lemma': 'slumm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('in', 'in')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Pekingi slummis')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10285</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>Laulupeo eelproovide</td>\n",
       "      <td>[Span('Laulupeo', [{'id': 1, 'lemma': 'laulupidu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('eelproovide', [{'id': 2, 'lemma': 'eelproov', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Laulupeo eelproovide käigus')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10286</th>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>koorijuhi palgamäära</td>\n",
       "      <td>[Span('koorijuhi', [{'id': 2, 'lemma': 'koorijuht', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('palgamäära', [{'id': 3, 'lemma': 'palgamäär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('p', 'p')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='ka koorijuhi palgamäära')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10287 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pattern            phrase_text  \\\n",
       "0      1 2 nmod S,2 0 root S         teede äärtesse   \n",
       "1      1 2 nmod H,2 0 root S         Tartu ülikooli   \n",
       "2      1 2 nmod S,2 0 root S        ülikooli ajaloo   \n",
       "3      1 2 nmod S,2 0 root S        ajaloo osakonna   \n",
       "4      1 2 nmod S,2 0 root S     osakonna üldajaloo   \n",
       "...                      ...                    ...   \n",
       "10282  1 2 nmod S,2 0 root S  normi ettekirjutusega   \n",
       "10283  1 2 nmod S,2 0 root S         õiguse subjekt   \n",
       "10284  1 2 nmod H,2 0 root S        Pekingi slummis   \n",
       "10285  1 2 nmod S,2 0 root S   Laulupeo eelproovide   \n",
       "10286  1 2 nmod S,2 0 root S   koorijuhi palgamäära   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               phrase_spans  \\\n",
       "0                                                   [Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('ill', 'ill')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "1                            [Span('Tartu', [{'id': 1, 'lemma': 'Tartu', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "2            [Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "3            [Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "4      [Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('üldajaloo', [{'id': 5, 'lemma': 'üldajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 6, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "10282                                           [Span('normi', [{'id': 1, 'lemma': 'norm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('ettekirjutusega', [{'id': 2, 'lemma': 'ettekirjutus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('kom', 'kom')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10283                                                          [Span('õiguse', [{'id': 1, 'lemma': 'õigus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('subjekt', [{'id': 2, 'lemma': 'subjekt', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10284                                                        [Span('Pekingi', [{'id': 1, 'lemma': 'Peking', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('slummis', [{'id': 2, 'lemma': 'slumm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('in', 'in')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10285                                               [Span('Laulupeo', [{'id': 1, 'lemma': 'laulupidu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('eelproovide', [{'id': 2, 'lemma': 'eelproov', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10286                                              [Span('koorijuhi', [{'id': 2, 'lemma': 'koorijuht', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('palgamäära', [{'id': 3, 'lemma': 'palgamäär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('p', 'p')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "\n",
       "                                                                                   parent_phrase  \n",
       "0                                                              Text(text='neist teede äärtesse')  \n",
       "1      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "2      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "3      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "4      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "...                                                                                          ...  \n",
       "10282                                                         Text(text='normi ettekirjutusega')  \n",
       "10283                                                                Text(text='õiguse subjekt')  \n",
       "10284                                                               Text(text='Pekingi slummis')  \n",
       "10285                                                   Text(text='Laulupeo eelproovide käigus')  \n",
       "10286                                                       Text(text='ka koorijuhi palgamäära')  \n",
       "\n",
       "[10287 rows x 4 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "0e44a9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER/TIMEX/OTHER\n",
    "combinations = []\n",
    "for idx, row in matches_df.iterrows():\n",
    "    combination = []\n",
    "    for stanza_word in row['phrase_spans']:\n",
    "        combination.append(get_ner_timex(row['parent_phrase'], stanza_word))\n",
    "    combinations.append(\"-\".join(combination))\n",
    "\n",
    "matches_df.insert(0, 'ner/timex/other', combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "5bb0fdc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner/timex/other</th>\n",
       "      <th>pattern</th>\n",
       "      <th>phrase_text</th>\n",
       "      <th>phrase_spans</th>\n",
       "      <th>parent_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>teede äärtesse</td>\n",
       "      <td>[Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('ill', 'ill')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='neist teede äärtesse')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORG-ORG</td>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>Tartu ülikooli</td>\n",
       "      <td>[Span('Tartu', [{'id': 1, 'lemma': 'Tartu', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORG-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>ülikooli ajaloo</td>\n",
       "      <td>[Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>ajaloo osakonna</td>\n",
       "      <td>[Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>osakonna üldajaloo</td>\n",
       "      <td>[Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}]), Span('üldajaloo', [{'id': 5, 'lemma': 'üldajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 6, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10282</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>normi ettekirjutusega</td>\n",
       "      <td>[Span('normi', [{'id': 1, 'lemma': 'norm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('ettekirjutusega', [{'id': 2, 'lemma': 'ettekirjutus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('kom', 'kom')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='normi ettekirjutusega')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10283</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>õiguse subjekt</td>\n",
       "      <td>[Span('õiguse', [{'id': 1, 'lemma': 'õigus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('subjekt', [{'id': 2, 'lemma': 'subjekt', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='õiguse subjekt')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10284</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>Pekingi slummis</td>\n",
       "      <td>[Span('Pekingi', [{'id': 1, 'lemma': 'Peking', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('slummis', [{'id': 2, 'lemma': 'slumm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('in', 'in')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Pekingi slummis')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10285</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>Laulupeo eelproovide</td>\n",
       "      <td>[Span('Laulupeo', [{'id': 1, 'lemma': 'laulupidu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('eelproovide', [{'id': 2, 'lemma': 'eelproov', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Laulupeo eelproovide käigus')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10286</th>\n",
       "      <td>OTHER-OTHER</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>koorijuhi palgamäära</td>\n",
       "      <td>[Span('koorijuhi', [{'id': 2, 'lemma': 'koorijuht', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('palgamäära', [{'id': 3, 'lemma': 'palgamäär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('p', 'p')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='ka koorijuhi palgamäära')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10287 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ner/timex/other                pattern            phrase_text  \\\n",
       "0         OTHER-OTHER  1 2 nmod S,2 0 root S         teede äärtesse   \n",
       "1             ORG-ORG  1 2 nmod H,2 0 root S         Tartu ülikooli   \n",
       "2           ORG-OTHER  1 2 nmod S,2 0 root S        ülikooli ajaloo   \n",
       "3         OTHER-OTHER  1 2 nmod S,2 0 root S        ajaloo osakonna   \n",
       "4         OTHER-OTHER  1 2 nmod S,2 0 root S     osakonna üldajaloo   \n",
       "...               ...                    ...                    ...   \n",
       "10282     OTHER-OTHER  1 2 nmod S,2 0 root S  normi ettekirjutusega   \n",
       "10283     OTHER-OTHER  1 2 nmod S,2 0 root S         õiguse subjekt   \n",
       "10284     OTHER-OTHER  1 2 nmod H,2 0 root S        Pekingi slummis   \n",
       "10285     OTHER-OTHER  1 2 nmod S,2 0 root S   Laulupeo eelproovide   \n",
       "10286     OTHER-OTHER  1 2 nmod S,2 0 root S   koorijuhi palgamäära   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               phrase_spans  \\\n",
       "0                                                   [Span('teede', [{'id': 2, 'lemma': 'tee', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('äärtesse', [{'id': 3, 'lemma': 'äär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('ill', 'ill')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "1                            [Span('Tartu', [{'id': 1, 'lemma': 'Tartu', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "2            [Span('ülikooli', [{'id': 2, 'lemma': 'ülikool', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "3            [Span('ajaloo', [{'id': 3, 'lemma': 'ajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 4, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "4      [Span('osakonna', [{'id': 4, 'lemma': 'osakond', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}]), Span('üldajaloo', [{'id': 5, 'lemma': 'üldajalugu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 6, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ...   \n",
       "10282                                           [Span('normi', [{'id': 1, 'lemma': 'norm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('ettekirjutusega', [{'id': 2, 'lemma': 'ettekirjutus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('kom', 'kom')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10283                                                          [Span('õiguse', [{'id': 1, 'lemma': 'õigus', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('subjekt', [{'id': 2, 'lemma': 'subjekt', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10284                                                        [Span('Pekingi', [{'id': 1, 'lemma': 'Peking', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('slummis', [{'id': 2, 'lemma': 'slumm', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('in', 'in')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10285                                               [Span('Laulupeo', [{'id': 1, 'lemma': 'laulupidu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 2, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('eelproovide', [{'id': 2, 'lemma': 'eelproov', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('pl', 'pl'), ('g', 'g')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "10286                                              [Span('koorijuhi', [{'id': 2, 'lemma': 'koorijuht', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('palgamäära', [{'id': 3, 'lemma': 'palgamäär', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('p', 'p')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "\n",
       "                                                                                   parent_phrase  \n",
       "0                                                              Text(text='neist teede äärtesse')  \n",
       "1      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "2      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "3      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "4      Text(text='Tartu ülikooli ajaloo osakonna üldajaloo õppetooli vanemlaborant Sirje Tamul')  \n",
       "...                                                                                          ...  \n",
       "10282                                                         Text(text='normi ettekirjutusega')  \n",
       "10283                                                                Text(text='õiguse subjekt')  \n",
       "10284                                                               Text(text='Pekingi slummis')  \n",
       "10285                                                   Text(text='Laulupeo eelproovide käigus')  \n",
       "10286                                                       Text(text='ka koorijuhi palgamäära')  \n",
       "\n",
       "[10287 rows x 5 columns]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "fc6a3afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df = matches_df.drop(columns=['pattern_status_ner_timex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d0926641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding information about pattern status (with ner/timex) -> 0 (pattern does not exist in pattern list), \n",
    "# 1 (pattern exists in pattern list)\n",
    "pattern_statuses = []\n",
    "for idx, row in matches_df.iterrows():\n",
    "    ner_timex = row['ner/timex/other'].split('-')\n",
    "    pattern_splitted = [part.split() for part in row['pattern'].split(',')]\n",
    "    for i in range(len(pattern_splitted)):\n",
    "        pattern_splitted[i].insert(1, ner_timex[i])\n",
    "    for i in range(len(pattern_splitted)):\n",
    "        pattern_splitted[i] = \" \".join(pattern_splitted[i])\n",
    "    new_pattern = \",\".join(pattern_splitted)\n",
    "    \n",
    "    if new_pattern in patterns:\n",
    "        pattern_statuses.append(1)\n",
    "    else:\n",
    "        pattern_statuses.append(0)\n",
    "\n",
    "matches_df.insert(2, 'pattern_status_ner_timex', pattern_statuses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "14b19070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with start and end positions of phrases\n",
    "phrase_startends = []\n",
    "for idx, row in matches_df.iterrows():\n",
    "    start = row['phrase_spans'][0].start\n",
    "    end = row['phrase_spans'][-1].end\n",
    "    phrase_startends.append([start, end])\n",
    "    \n",
    "matches_df.insert(4, 'startend', phrase_startends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "132f1f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_df_sorted = matches_df.sort_values(by=['ner/timex/other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "4d2fa6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ner/timex/other</th>\n",
       "      <th>pattern</th>\n",
       "      <th>pattern_status_ner_timex</th>\n",
       "      <th>phrase_text</th>\n",
       "      <th>startend</th>\n",
       "      <th>phrase_spans</th>\n",
       "      <th>parent_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7647</th>\n",
       "      <td>LOC-LOC</td>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mustvee linn</td>\n",
       "      <td>[94, 106]</td>\n",
       "      <td>[Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7641</th>\n",
       "      <td>LOC-LOC</td>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mustvee linn</td>\n",
       "      <td>[94, 106]</td>\n",
       "      <td>[Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7640</th>\n",
       "      <td>LOC-LOC</td>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mustvee linn</td>\n",
       "      <td>[94, 106]</td>\n",
       "      <td>[Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>LOC-LOC</td>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>Mustvee linn</td>\n",
       "      <td>[94, 106]</td>\n",
       "      <td>[Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7638</th>\n",
       "      <td>LOC-LOC</td>\n",
       "      <td>1 2 nmod H,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>Elva linn</td>\n",
       "      <td>[66, 75]</td>\n",
       "      <td>[Span('Elva', [{'id': 15, 'lemma': 'Elva', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 16, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('linn', [{'id': 16, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>TIMEX-TIMEX</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>varahommikust hilisõhtuni</td>\n",
       "      <td>[41, 66]</td>\n",
       "      <td>[Span('varahommikust', [{'id': 8, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 9, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('hilisõhtuni', [{'id': 9, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Kogu töötamise aja - 30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised .')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6012</th>\n",
       "      <td>TIMEX-TIMEX</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>varahommikust hilisõhtuni</td>\n",
       "      <td>[20, 45]</td>\n",
       "      <td>[Span('varahommikust', [{'id': 4, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('hilisõhtuni', [{'id': 5, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'obl', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>TIMEX-TIMEX</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>varahommikust hilisõhtuni</td>\n",
       "      <td>[20, 45]</td>\n",
       "      <td>[Span('varahommikust', [{'id': 4, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('hilisõhtuni', [{'id': 5, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'obl', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6010</th>\n",
       "      <td>TIMEX-TIMEX</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>varahommikust hilisõhtuni</td>\n",
       "      <td>[20, 45]</td>\n",
       "      <td>[Span('varahommikust', [{'id': 4, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('hilisõhtuni', [{'id': 5, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'obl', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>TIMEX-TIMEX</td>\n",
       "      <td>1 2 nmod S,2 0 root S</td>\n",
       "      <td>0</td>\n",
       "      <td>kesknädala pärastlõunal</td>\n",
       "      <td>[7, 30]</td>\n",
       "      <td>[Span('kesknädala', [{'id': 2, 'lemma': 'kesknädal', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': &lt;class 'estnltk_core.layer.span.Span'&gt;, 'children': ()}]), Span('pärastlõunal', [{'id': 3, 'lemma': 'pärastlõuna', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ad', 'ad')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': &lt;class 'tuple'&gt;}])]</td>\n",
       "      <td>Text(text='Sellel kesknädala pärastlõunal')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10287 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ner/timex/other                pattern  pattern_status_ner_timex  \\\n",
       "7647         LOC-LOC  1 2 nmod H,2 0 root S                         0   \n",
       "7641         LOC-LOC  1 2 nmod H,2 0 root S                         0   \n",
       "7640         LOC-LOC  1 2 nmod H,2 0 root S                         0   \n",
       "7639         LOC-LOC  1 2 nmod H,2 0 root S                         0   \n",
       "7638         LOC-LOC  1 2 nmod H,2 0 root S                         0   \n",
       "...              ...                    ...                       ...   \n",
       "1083     TIMEX-TIMEX  1 2 nmod S,2 0 root S                         0   \n",
       "6012     TIMEX-TIMEX  1 2 nmod S,2 0 root S                         0   \n",
       "6011     TIMEX-TIMEX  1 2 nmod S,2 0 root S                         0   \n",
       "6010     TIMEX-TIMEX  1 2 nmod S,2 0 root S                         0   \n",
       "6239     TIMEX-TIMEX  1 2 nmod S,2 0 root S                         0   \n",
       "\n",
       "                    phrase_text   startend  \\\n",
       "7647               Mustvee linn  [94, 106]   \n",
       "7641               Mustvee linn  [94, 106]   \n",
       "7640               Mustvee linn  [94, 106]   \n",
       "7639               Mustvee linn  [94, 106]   \n",
       "7638                  Elva linn   [66, 75]   \n",
       "...                         ...        ...   \n",
       "1083  varahommikust hilisõhtuni   [41, 66]   \n",
       "6012  varahommikust hilisõhtuni   [20, 45]   \n",
       "6011  varahommikust hilisõhtuni   [20, 45]   \n",
       "6010  varahommikust hilisõhtuni   [20, 45]   \n",
       "6239    kesknädala pärastlõunal    [7, 30]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                phrase_spans  \\\n",
       "7647                          [Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "7641                          [Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "7640                          [Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "7639                          [Span('Mustvee', [{'id': 21, 'lemma': 'Mustvee', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 22, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('linn', [{'id': 22, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "7638                                [Span('Elva', [{'id': 15, 'lemma': 'Elva', 'upostag': 'H', 'xpostag': 'H', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 16, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('linn', [{'id': 16, 'lemma': 'linn', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('n', 'n')]), 'head': 2, 'deprel': 'conj', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
       "1083  [Span('varahommikust', [{'id': 8, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 9, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('hilisõhtuni', [{'id': 9, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "6012   [Span('varahommikust', [{'id': 4, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('hilisõhtuni', [{'id': 5, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'obl', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "6011   [Span('varahommikust', [{'id': 4, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('hilisõhtuni', [{'id': 5, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'obl', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "6010   [Span('varahommikust', [{'id': 4, 'lemma': 'varahommik', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('el', 'el')]), 'head': 5, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('hilisõhtuni', [{'id': 5, 'lemma': 'hilisõhtu', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ter', 'ter')]), 'head': 3, 'deprel': 'obl', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': <class 'tuple'>}])]   \n",
       "6239                                         [Span('kesknädala', [{'id': 2, 'lemma': 'kesknädal', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('g', 'g')]), 'head': 3, 'deprel': 'nmod', 'deps': '_', 'misc': '_', 'parent_span': <class 'estnltk_core.layer.span.Span'>, 'children': ()}]), Span('pärastlõunal', [{'id': 3, 'lemma': 'pärastlõuna', 'upostag': 'S', 'xpostag': 'S', 'feats': OrderedDict([('sg', 'sg'), ('ad', 'ad')]), 'head': 0, 'deprel': 'root', 'deps': '_', 'misc': '_', 'parent_span': None, 'children': <class 'tuple'>}])]   \n",
       "\n",
       "                                                                                                                                                                                           parent_phrase  \n",
       "7647  Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')  \n",
       "7641  Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')  \n",
       "7640  Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')  \n",
       "7639  Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')  \n",
       "7638  Text(text='Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus')  \n",
       "...                                                                                                                                                                                                  ...  \n",
       "1083                                                                                                  Text(text='Kogu töötamise aja - 30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised .')  \n",
       "6012                                                                                                                         Text(text='30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised')  \n",
       "6011                                                                                                                         Text(text='30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised')  \n",
       "6010                                                                                                                         Text(text='30 aastat ühtejärge varahommikust hilisõhtuni nagu kõik naised')  \n",
       "6239                                                                                                                                                         Text(text='Sellel kesknädala pärastlõunal')  \n",
       "\n",
       "[10287 rows x 7 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1f1a8c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x166625b79c0>"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"noun_phrases.db\")\n",
    "cur = con.cursor()\n",
    "cur.execute('pragma encoding=UTF8')\n",
    "cur.execute(\"CREATE TABLE correct_phrase_patterns(ID INTEGER PRIMARY KEY, ner_timex_other TEXT, pattern TEXT, pattern_status_ner_timex INTEGER, phrase_text TEXT, startend TEXT, parent_phrase TEXT)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "3922ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "84a765f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"Tartu linn ja selle ümbrus , Põlva linn ja selle ümbrus , Rõngu , Elva linn ja selle ümbrus , Mustvee linn ja selle ümbrus , Kuuste , Alatskivi , Puhja , Otepää linn ja selle ümbrus\", \"meta\": {\"document_creation_time\": \"2024-03-10T01:12\", \"sentence_id\": 1474958, \"document_id\": 59053, \"sentence_startend\": [446, 644], \"subcorpus\": \"aja_EPL\", \"phrase_type\": \"nsubj_phrase\", \"phrase_start_end\": [15, 196]}, \"layers\": [{\"name\": \"timexes\", \"attributes\": [\"tid\", \"type\", \"value\", \"temporal_function\", \"anchor_time_id\", \"mod\", \"quant\", \"freq\", \"begin_point\", \"end_point\", \"part_of_interval\"], \"secondary_attributes\": [], \"parent\": null, \"enveloping\": null, \"ambiguous\": false, \"serialisation_module\": null, \"meta\": {}, \"spans\": []}, {\"name\": \"tokens\", \"attributes\": [], \"secondary_attributes\": [], \"parent\": null, \"enveloping\": null, \"ambiguous\": false, \"serialisation_module\": null, \"meta\": {}, \"spans\": [{\"base_span\": [0, 5], \"annotations\": [{}]}, {\"base_span\": [6, 10], \"annotations\": [{}]}, {\"base_span\": [11, 13], \"annotations\": [{}]}, {\"base_span\": [14, 19], \"annotations\": [{}]}, {\"base_span\": [20, 26], \"annotations\": [{}]}, {\"base_span\": [27, 28], \"annotations\": [{}]}, {\"base_span\": [29, 34], \"annotations\": [{}]}, {\"base_span\": [35, 39], \"annotations\": [{}]}, {\"base_span\": [40, 42], \"annotations\": [{}]}, {\"base_span\": [43, 48], \"annotations\": [{}]}, {\"base_span\": [49, 55], \"annotations\": [{}]}, {\"base_span\": [56, 57], \"annotations\": [{}]}, {\"base_span\": [58, 63], \"annotations\": [{}]}, {\"base_span\": [64, 65], \"annotations\": [{}]}, {\"base_span\": [66, 70], \"annotations\": [{}]}, {\"base_span\": [71, 75], \"annotations\": [{}]}, {\"base_span\": [76, 78], \"annotations\": [{}]}, {\"base_span\": [79, 84], \"annotations\": [{}]}, {\"base_span\": [85, 91], \"annotations\": [{}]}, {\"base_span\": [92, 93], \"annotations\": [{}]}, {\"base_span\": [94, 101], \"annotations\": [{}]}, {\"base_span\": [102, 106], \"annotations\": [{}]}, {\"base_span\": [107, 109], \"annotations\": [{}]}, {\"base_span\": [110, 115], \"annotations\": [{}]}, {\"base_span\": [116, 122], \"annotations\": [{}]}, {\"base_span\": [123, 124], \"annotations\": [{}]}, {\"base_span\": [125, 131], \"annotations\": [{}]}, {\"base_span\": [132, 133], \"annotations\": [{}]}, {\"base_span\": [134, 143], \"annotations\": [{}]}, {\"base_span\": [144, 145], \"annotations\": [{}]}, {\"base_span\": [146, 151], \"annotations\": [{}]}, {\"base_span\": [152, 153], \"annotations\": [{}]}, {\"base_span\": [154, 160], \"annotations\": [{}]}, {\"base_span\": [161, 165], \"annotations\": [{}]}, {\"base_span\": [166, 168], \"annotations\": [{}]}, {\"base_span\": [169, 174], \"annotations\": [{}]}, {\"base_span\": [175, 181], \"annotations\": [{}]}]}, {\"name\": \"compound_tokens\", \"attributes\": [\"type\", \"normalized\"], \"secondary_attributes\": [], \"parent\": null, \"enveloping\": \"tokens\", \"ambiguous\": false, \"serialisation_module\": null, \"meta\": {}, \"spans\": []}, {\"name\": \"words\", \"attributes\": [\"normalized_form\"], \"secondary_attributes\": [], \"parent\": null, \"enveloping\": null, \"ambiguous\": true, \"serialisation_module\": null, \"meta\": {}, \"spans\": [{\"base_span\": [0, 5], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [6, 10], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [11, 13], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [14, 19], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [20, 26], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [27, 28], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [29, 34], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [35, 39], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [40, 42], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [43, 48], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [49, 55], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [56, 57], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [58, 63], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [64, 65], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [66, 70], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [71, 75], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [76, 78], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [79, 84], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [85, 91], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [92, 93], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [94, 101], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [102, 106], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [107, 109], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [110, 115], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [116, 122], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [123, 124], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [125, 131], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [132, 133], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [134, 143], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [144, 145], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [146, 151], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [152, 153], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [154, 160], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [161, 165], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [166, 168], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [169, 174], \"annotations\": [{\"normalized_form\": null}]}, {\"base_span\": [175, 181], \"annotations\": [{\"normalized_form\": null}]}]}, {\"name\": \"morph_analysis\", \"attributes\": [\"normalized_text\", \"lemma\", \"root\", \"root_tokens\", \"ending\", \"clitic\", \"form\", \"partofspeech\"], \"secondary_attributes\": [], \"parent\": \"words\", \"enveloping\": null, \"ambiguous\": true, \"serialisation_module\": null, \"meta\": {}, \"spans\": [{\"base_span\": [0, 5], \"annotations\": [{\"normalized_text\": \"Tartu\", \"lemma\": \"Tartu\", \"root\": \"Tartu\", \"root_tokens\": [\"Tartu\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [6, 10], \"annotations\": [{\"normalized_text\": \"linn\", \"lemma\": \"linn\", \"root\": \"linn\", \"root_tokens\": [\"linn\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [11, 13], \"annotations\": [{\"normalized_text\": \"ja\", \"lemma\": \"ja\", \"root\": \"ja\", \"root_tokens\": [\"ja\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"J\"}]}, {\"base_span\": [14, 19], \"annotations\": [{\"normalized_text\": \"selle\", \"lemma\": \"see\", \"root\": \"see\", \"root_tokens\": [\"see\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"P\"}]}, {\"base_span\": [20, 26], \"annotations\": [{\"normalized_text\": \"ümbrus\", \"lemma\": \"ümbrus\", \"root\": \"ümbrus\", \"root_tokens\": [\"ümbrus\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [27, 28], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [29, 34], \"annotations\": [{\"normalized_text\": \"Põlva\", \"lemma\": \"Põlva\", \"root\": \"Põlva\", \"root_tokens\": [\"Põlva\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [35, 39], \"annotations\": [{\"normalized_text\": \"linn\", \"lemma\": \"linn\", \"root\": \"linn\", \"root_tokens\": [\"linn\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [40, 42], \"annotations\": [{\"normalized_text\": \"ja\", \"lemma\": \"ja\", \"root\": \"ja\", \"root_tokens\": [\"ja\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"J\"}]}, {\"base_span\": [43, 48], \"annotations\": [{\"normalized_text\": \"selle\", \"lemma\": \"see\", \"root\": \"see\", \"root_tokens\": [\"see\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"P\"}]}, {\"base_span\": [49, 55], \"annotations\": [{\"normalized_text\": \"ümbrus\", \"lemma\": \"ümbrus\", \"root\": \"ümbrus\", \"root_tokens\": [\"ümbrus\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [56, 57], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [58, 63], \"annotations\": [{\"normalized_text\": \"Rõngu\", \"lemma\": \"Rõngu\", \"root\": \"Rõngu\", \"root_tokens\": [\"Rõngu\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [64, 65], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [66, 70], \"annotations\": [{\"normalized_text\": \"Elva\", \"lemma\": \"Elva\", \"root\": \"Elva\", \"root_tokens\": [\"Elva\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [71, 75], \"annotations\": [{\"normalized_text\": \"linn\", \"lemma\": \"linn\", \"root\": \"linn\", \"root_tokens\": [\"linn\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [76, 78], \"annotations\": [{\"normalized_text\": \"ja\", \"lemma\": \"ja\", \"root\": \"ja\", \"root_tokens\": [\"ja\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"J\"}]}, {\"base_span\": [79, 84], \"annotations\": [{\"normalized_text\": \"selle\", \"lemma\": \"see\", \"root\": \"see\", \"root_tokens\": [\"see\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"P\"}]}, {\"base_span\": [85, 91], \"annotations\": [{\"normalized_text\": \"ümbrus\", \"lemma\": \"ümbrus\", \"root\": \"ümbrus\", \"root_tokens\": [\"ümbrus\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [92, 93], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [94, 101], \"annotations\": [{\"normalized_text\": \"Mustvee\", \"lemma\": \"Mustvee\", \"root\": \"Must_vee\", \"root_tokens\": [\"Must\", \"vee\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [102, 106], \"annotations\": [{\"normalized_text\": \"linn\", \"lemma\": \"linn\", \"root\": \"linn\", \"root_tokens\": [\"linn\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [107, 109], \"annotations\": [{\"normalized_text\": \"ja\", \"lemma\": \"ja\", \"root\": \"ja\", \"root_tokens\": [\"ja\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"J\"}]}, {\"base_span\": [110, 115], \"annotations\": [{\"normalized_text\": \"selle\", \"lemma\": \"see\", \"root\": \"see\", \"root_tokens\": [\"see\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"P\"}]}, {\"base_span\": [116, 122], \"annotations\": [{\"normalized_text\": \"ümbrus\", \"lemma\": \"ümbrus\", \"root\": \"ümbrus\", \"root_tokens\": [\"ümbrus\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [123, 124], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [125, 131], \"annotations\": [{\"normalized_text\": \"Kuuste\", \"lemma\": \"Kuune\", \"root\": \"Kuune\", \"root_tokens\": [\"Kuune\"], \"ending\": \"te\", \"clitic\": \"\", \"form\": \"pl g\", \"partofspeech\": \"H\"}, {\"normalized_text\": \"Kuuste\", \"lemma\": \"Kuuste\", \"root\": \"Kuuste\", \"root_tokens\": [\"Kuuste\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [132, 133], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [134, 143], \"annotations\": [{\"normalized_text\": \"Alatskivi\", \"lemma\": \"Alatskivi\", \"root\": \"Alats_kivi\", \"root_tokens\": [\"Alats\", \"kivi\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [144, 145], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [146, 151], \"annotations\": [{\"normalized_text\": \"Puhja\", \"lemma\": \"Puhja\", \"root\": \"Puhja\", \"root_tokens\": [\"Puhja\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [152, 153], \"annotations\": [{\"normalized_text\": \",\", \"lemma\": \",\", \"root\": \",\", \"root_tokens\": [\",\"], \"ending\": \"\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"Z\"}]}, {\"base_span\": [154, 160], \"annotations\": [{\"normalized_text\": \"Otepää\", \"lemma\": \"Otepää\", \"root\": \"Otepää\", \"root_tokens\": [\"Otepää\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"H\"}]}, {\"base_span\": [161, 165], \"annotations\": [{\"normalized_text\": \"linn\", \"lemma\": \"linn\", \"root\": \"linn\", \"root_tokens\": [\"linn\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}, {\"base_span\": [166, 168], \"annotations\": [{\"normalized_text\": \"ja\", \"lemma\": \"ja\", \"root\": \"ja\", \"root_tokens\": [\"ja\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"\", \"partofspeech\": \"J\"}]}, {\"base_span\": [169, 174], \"annotations\": [{\"normalized_text\": \"selle\", \"lemma\": \"see\", \"root\": \"see\", \"root_tokens\": [\"see\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg g\", \"partofspeech\": \"P\"}]}, {\"base_span\": [175, 181], \"annotations\": [{\"normalized_text\": \"ümbrus\", \"lemma\": \"ümbrus\", \"root\": \"ümbrus\", \"root_tokens\": [\"ümbrus\"], \"ending\": \"0\", \"clitic\": \"\", \"form\": \"sg n\", \"partofspeech\": \"S\"}]}]}, {\"name\": \"ner\", \"attributes\": [\"nertag\"], \"secondary_attributes\": [], \"parent\": null, \"enveloping\": \"words\", \"ambiguous\": false, \"serialisation_module\": null, \"meta\": {}, \"spans\": [{\"base_span\": [[0, 5], [6, 10]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[29, 34], [35, 39]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[58, 63]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[66, 70], [71, 75]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[94, 101], [102, 106]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[125, 131]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[134, 143]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[146, 151]], \"annotations\": [{\"nertag\": \"LOC\"}]}, {\"base_span\": [[154, 160], [161, 165]], \"annotations\": [{\"nertag\": \"LOC\"}]}]}, {\"name\": \"sentences\", \"attributes\": [], \"secondary_attributes\": [], \"parent\": null, \"enveloping\": \"words\", \"ambiguous\": false, \"serialisation_module\": null, \"meta\": {}, \"spans\": [{\"base_span\": [[0, 5], [6, 10], [11, 13], [14, 19], [20, 26], [27, 28], [29, 34], [35, 39], [40, 42], [43, 48], [49, 55], [56, 57], [58, 63], [64, 65], [66, 70], [71, 75], [76, 78], [79, 84], [85, 91], [92, 93], [94, 101], [102, 106], [107, 109], [110, 115], [116, 122], [123, 124], [125, 131], [132, 133], [134, 143], [144, 145], [146, 151], [152, 153], [154, 160], [161, 165], [166, 168], [169, 174], [175, 181]], \"annotations\": [{}]}]}, {\"name\": \"stanza_syntax\", \"attributes\": [\"id\", \"lemma\", \"upostag\", \"xpostag\", \"feats\", \"head\", \"deprel\", \"deps\", \"misc\", \"parent_span\", \"children\"], \"secondary_attributes\": [\"parent_span\", \"children\"], \"parent\": \"morph_analysis\", \"enveloping\": null, \"ambiguous\": false, \"serialisation_module\": \"syntax_v0\", \"meta\": {}, \"spans\": [{\"base_span\": [0, 5], \"annotations\": [{\"id\": 1, \"lemma\": \"Tartu\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 2, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [6, 10], \"annotations\": [{\"id\": 2, \"lemma\": \"linn\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 0, \"deprel\": \"root\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [11, 13], \"annotations\": [{\"id\": 3, \"lemma\": \"ja\", \"upostag\": \"J\", \"xpostag\": \"J\", \"feats\": {}, \"head\": 5, \"deprel\": \"cc\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [14, 19], \"annotations\": [{\"id\": 4, \"lemma\": \"see\", \"upostag\": \"P\", \"xpostag\": \"P\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 5, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [20, 26], \"annotations\": [{\"id\": 5, \"lemma\": \"ümbrus\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [27, 28], \"annotations\": [{\"id\": 6, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 8, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [29, 34], \"annotations\": [{\"id\": 7, \"lemma\": \"Põlva\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 8, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [35, 39], \"annotations\": [{\"id\": 8, \"lemma\": \"linn\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [40, 42], \"annotations\": [{\"id\": 9, \"lemma\": \"ja\", \"upostag\": \"J\", \"xpostag\": \"J\", \"feats\": {}, \"head\": 11, \"deprel\": \"cc\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [43, 48], \"annotations\": [{\"id\": 10, \"lemma\": \"see\", \"upostag\": \"P\", \"xpostag\": \"P\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 11, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [49, 55], \"annotations\": [{\"id\": 11, \"lemma\": \"ümbrus\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [56, 57], \"annotations\": [{\"id\": 12, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 13, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [58, 63], \"annotations\": [{\"id\": 13, \"lemma\": \"Rõngu\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [64, 65], \"annotations\": [{\"id\": 14, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 16, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [66, 70], \"annotations\": [{\"id\": 15, \"lemma\": \"Elva\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 16, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [71, 75], \"annotations\": [{\"id\": 16, \"lemma\": \"linn\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [76, 78], \"annotations\": [{\"id\": 17, \"lemma\": \"ja\", \"upostag\": \"J\", \"xpostag\": \"J\", \"feats\": {}, \"head\": 19, \"deprel\": \"cc\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [79, 84], \"annotations\": [{\"id\": 18, \"lemma\": \"see\", \"upostag\": \"P\", \"xpostag\": \"P\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 19, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [85, 91], \"annotations\": [{\"id\": 19, \"lemma\": \"ümbrus\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [92, 93], \"annotations\": [{\"id\": 20, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 22, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [94, 101], \"annotations\": [{\"id\": 21, \"lemma\": \"Mustvee\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 22, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [102, 106], \"annotations\": [{\"id\": 22, \"lemma\": \"linn\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [107, 109], \"annotations\": [{\"id\": 23, \"lemma\": \"ja\", \"upostag\": \"J\", \"xpostag\": \"J\", \"feats\": {}, \"head\": 25, \"deprel\": \"cc\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [110, 115], \"annotations\": [{\"id\": 24, \"lemma\": \"see\", \"upostag\": \"P\", \"xpostag\": \"P\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 25, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [116, 122], \"annotations\": [{\"id\": 25, \"lemma\": \"ümbrus\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [123, 124], \"annotations\": [{\"id\": 26, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 27, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [125, 131], \"annotations\": [{\"id\": 27, \"lemma\": \"Kuune\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"pl\": \"pl\", \"g\": \"g\"}, \"head\": 34, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [132, 133], \"annotations\": [{\"id\": 28, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 29, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [134, 143], \"annotations\": [{\"id\": 29, \"lemma\": \"Alatskivi\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 27, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [144, 145], \"annotations\": [{\"id\": 30, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 31, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [146, 151], \"annotations\": [{\"id\": 31, \"lemma\": \"Puhja\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 27, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [152, 153], \"annotations\": [{\"id\": 32, \"lemma\": \",\", \"upostag\": \"Z\", \"xpostag\": \"Z\", \"feats\": {}, \"head\": 34, \"deprel\": \"punct\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [154, 160], \"annotations\": [{\"id\": 33, \"lemma\": \"Otepää\", \"upostag\": \"H\", \"xpostag\": \"H\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 27, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [161, 165], \"annotations\": [{\"id\": 34, \"lemma\": \"linn\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [166, 168], \"annotations\": [{\"id\": 35, \"lemma\": \"ja\", \"upostag\": \"J\", \"xpostag\": \"J\", \"feats\": {}, \"head\": 37, \"deprel\": \"cc\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [169, 174], \"annotations\": [{\"id\": 36, \"lemma\": \"see\", \"upostag\": \"P\", \"xpostag\": \"P\", \"feats\": {\"sg\": \"sg\", \"g\": \"g\"}, \"head\": 37, \"deprel\": \"nmod\", \"deps\": \"_\", \"misc\": \"_\"}]}, {\"base_span\": [175, 181], \"annotations\": [{\"id\": 37, \"lemma\": \"ümbrus\", \"upostag\": \"S\", \"xpostag\": \"S\", \"feats\": {\"sg\": \"sg\", \"n\": \"n\"}, \"head\": 2, \"deprel\": \"conj\", \"deps\": \"_\", \"misc\": \"_\"}]}]}], \"relation_layers\": []}\n",
      "[94, 106]\n"
     ]
    }
   ],
   "source": [
    "for idx, row in matches_df_sorted.iterrows():\n",
    "    print(text_to_json(row['parent_phrase']))\n",
    "    stri = str(row['startend'])\n",
    "    print(eval(stri))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "c9afc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"noun_phrases.db\")\n",
    "cur = con.cursor()\n",
    "\n",
    "for idx, row in matches_df_sorted.iterrows():\n",
    "    parent_phrase_json = text_to_json(row['parent_phrase'])\n",
    "    startend_str = str(row['startend'])\n",
    "    cur.execute(\"\"\"INSERT INTO correct_phrase_patterns\n",
    "                            (ner_timex_other, pattern, pattern_status_ner_timex, phrase_text, startend, parent_phrase)\n",
    "                            VALUES (?, ?, ?, ?, ?, ?);\"\"\", (row['ner/timex/other'], row['pattern'], row['pattern_status_ner_timex'], row['phrase_text'], startend_str, parent_phrase_json))\n",
    "    \n",
    "    con.commit()\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a654e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
