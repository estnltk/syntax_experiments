{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax Augmentation with BERT\n",
    "\n",
    "### Requirements: \n",
    "* pytorch (1.7.0) <br>\n",
    "* transformers (3.1.0) <br>\n",
    "\n",
    "First time initializing the class will take some time as it will download the EstBERT model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # pytorch-1.7.0\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer # transformers-3.1.0\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "class BertSyntaxAugmenter():\n",
    "    def __init__(self, model_name:str='tartuNLP/EstBERT_512'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelWithLMHead.from_pretrained(model_name, return_dict=True)\n",
    "        \n",
    "        \n",
    "    def predict_10_mask(self, sentence:list)->(list, list, int):\n",
    "        # chooses random word, replaces it with 10 different words predicted by BERT \n",
    "        seq = deepcopy(sentence)\n",
    "        mask1 = random.choice([i for i in range(len(sentence))])\n",
    "        seq[mask1] = '[MASK]'\n",
    "        sequence = ' '.join(seq)\n",
    "        input = self.tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "        mask_token_index = torch.where(input == self.tokenizer.mask_token_id)[1]\n",
    "\n",
    "        token_logits = self.model(input).logits\n",
    "        mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "        top_10_tokens = torch.topk(mask_token_logits, 10, dim=1).indices[0].tolist()\n",
    "        \n",
    "        tokens, texts = [], []\n",
    "        for token in top_10_tokens:\n",
    "            tokens.append(self.tokenizer.decode([token]))\n",
    "            texts.append(sequence.replace(self.tokenizer.mask_token, self.tokenizer.decode([token])))\n",
    "\n",
    "        return tokens, texts, mask1\n",
    "    \n",
    "    \n",
    "    def predict_x_many_to_i(self,sentence:list, x:int, i:int)->(list, list):\n",
    "        # predicts x new words to replace word in i-th place\n",
    "        seq = deepcopy(sentence)\n",
    "        seq[i] = '[MASK]'\n",
    "        sequence = ' '.join(seq)\n",
    "        input = self.tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "        mask_token_index = torch.where(input == self.tokenizer.mask_token_id)[1]\n",
    "\n",
    "        token_logits = self.model(input).logits\n",
    "        mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "        top_x_tokens = torch.topk(mask_token_logits,x, dim=1).indices[0].tolist()\n",
    "        tokens, texts = [], []\n",
    "        for token in top_x_tokens:\n",
    "            tokens.append(self.tokenizer.decode([token]))\n",
    "            texts.append(sequence.replace(self.tokenizer.mask_token, self.tokenizer.decode([token])))\n",
    "\n",
    "        return tokens, texts\n",
    "    \n",
    "    def predict_mask_constraint(self, sentence:list, poses:list, suitable_pos:set, x:int)->(list, list, int):\n",
    "        # filters words based on their POS, predicts x words to suitable index\n",
    "        seq = deepcopy(sentence)\n",
    "        mask1 = random.choice([i for i, word in enumerate(sentence) if poses[i] in pos ])\n",
    "        seq[mask1] = '[MASK]'\n",
    "        sequence = ' '.join(seq)\n",
    "        input = self.tokenizer.encode(sequence, return_tensors=\"pt\")\n",
    "        mask_token_index = torch.where(input == self.tokenizer.mask_token_id)[1]\n",
    "\n",
    "        token_logits = self.model(input).logits\n",
    "        mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "        top_x_tokens = torch.topk(mask_token_logits, x, dim=1).indices[0].tolist()\n",
    "        tokens, texts = [], []\n",
    "        for token in top_x_tokens:\n",
    "            tokens.append(self.tokenizer.decode([token]))\n",
    "            texts.append(sequence.replace(self.tokenizer.mask_token, self.tokenizer.decode([token])))\n",
    "\n",
    "        return tokens, texts, mask1\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the bert model and tokenizer: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kittask\\anaconda3\\envs\\nlp\\lib\\site-packages\\transformers\\modeling_auto.py:821: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  FutureWarning,\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at tartuNLP/EstBERT_512 and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "augmenter = BertSyntaxAugmenter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can predict the word in a sentence in different ways. For that, BertSyntaxAugmenter have some methods that we can use. It is possible to add your own if these are not doing what is needed, It should be easy to do following the already implemented ones.\n",
    "\n",
    "First, we can predict 10 words to replace randomly chosen word from sentence with method predict_10_mask. Sentence should be a list. It will return all the words predicted in a list, all the new sentences created and the index, where the word was replaced in the sentece. \n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['kujuneb',\n",
       "  'muutub',\n",
       "  'jääb',\n",
       "  'kujunes',\n",
       "  'on',\n",
       "  'saab',\n",
       "  'sõltub',\n",
       "  'muutuks',\n",
       "  'kujunevad',\n",
       "  'areneb'],\n",
       " ['Milliseks kujuneb Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks muutub Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks jääb Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks kujunes Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks on Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks saab Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks sõltub Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks muutuks Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks kujunevad Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks areneb Riigikassa ja Ühispanga vahekord ?'],\n",
       " 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = ['Milliseks', 'kujuneb', 'Riigikassa', 'ja', 'Ühispanga', 'vahekord', '?']\n",
    "augmenter.predict_10_mask(sentence=sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, we can customize how many words we want to be predicted and to where with method predict_x_many_to_i. Output is the same except no index is returned. \n",
    "\n",
    "Example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['kujuneb', 'muutub'],\n",
       " ['Milliseks kujuneb Riigikassa ja Ühispanga vahekord ?',\n",
       "  'Milliseks muutub Riigikassa ja Ühispanga vahekord ?'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmenter.predict_x_many_to_i(sentence=sentence, x=2, i=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third, we can filter the suitable indices by POS tags. We can do that with method predict_mask_constraint.\n",
    "\n",
    "Example (only predicting to place where POS is S): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "text = Text(' '.join(sentence))\n",
    "text.analyse('all')\n",
    "poses = [pos[0] for pos in text.morph_analysis.partofspeech] # need to put all POS tags to a list\n",
    "pos = {'S'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P', 'V', 'S', 'J', 'H', 'S', 'Z']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mõju', 'suhe', 'vahel'],\n",
       " ['Milliseks kujuneb Riigikassa ja Ühispanga mõju ?',\n",
       "  'Milliseks kujuneb Riigikassa ja Ühispanga suhe ?',\n",
       "  'Milliseks kujuneb Riigikassa ja Ühispanga vahel ?'],\n",
       " 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmenter.predict_mask_constraint(sentence=sentence, poses=poses, suitable_pos=pos, x=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}